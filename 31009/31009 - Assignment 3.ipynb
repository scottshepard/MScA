{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31009 - Assignment 3: PCA & Logistic Regression\n",
    "\n",
    "Built a logistic regression model on the `ProviderInfo` dataset. Then use PCA to reduce dimensionality and build two new models on the PCA dataset: one with two components and one with sixteen compontents. Compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/ProviderInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_SSA</th>\n",
       "      <th>BEDCERT</th>\n",
       "      <th>RESTOT</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "      <th>SURVEY_RATING</th>\n",
       "      <th>QUALITY_RATING</th>\n",
       "      <th>STAFFING_RATING</th>\n",
       "      <th>RN_STAFFING_RATING</th>\n",
       "      <th>AIDHRD</th>\n",
       "      <th>VOCHRD</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ_AIDE</th>\n",
       "      <th>ADJ_LPN</th>\n",
       "      <th>ADJ_RN</th>\n",
       "      <th>ADJ_TOTAL</th>\n",
       "      <th>INCIDENT_CNT</th>\n",
       "      <th>CMPLNT_CNT</th>\n",
       "      <th>FINE_CNT</th>\n",
       "      <th>FINE_TOT</th>\n",
       "      <th>PAYDEN_CNT</th>\n",
       "      <th>TOT_PENLTY_CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.43572</td>\n",
       "      <td>1.16495</td>\n",
       "      <td>...</td>\n",
       "      <td>3.11741</td>\n",
       "      <td>1.24750</td>\n",
       "      <td>0.83853</td>\n",
       "      <td>5.13047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.32722</td>\n",
       "      <td>0.82104</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40074</td>\n",
       "      <td>0.86962</td>\n",
       "      <td>0.56463</td>\n",
       "      <td>3.83026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.33617</td>\n",
       "      <td>0.92407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55126</td>\n",
       "      <td>1.08955</td>\n",
       "      <td>0.30360</td>\n",
       "      <td>3.95709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>410.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>119.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.57869</td>\n",
       "      <td>1.01443</td>\n",
       "      <td>...</td>\n",
       "      <td>2.56783</td>\n",
       "      <td>1.04823</td>\n",
       "      <td>0.46444</td>\n",
       "      <td>4.07866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.99985</td>\n",
       "      <td>0.62768</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12102</td>\n",
       "      <td>0.70311</td>\n",
       "      <td>0.75448</td>\n",
       "      <td>3.52979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNTY_SSA  BEDCERT  RESTOT  OVERALL_RATING  SURVEY_RATING  QUALITY_RATING  \\\n",
       "0       290.0     57.0    51.5             5.0            5.0             5.0   \n",
       "3       360.0     92.0    79.8             2.0            2.0             4.0   \n",
       "4       360.0    103.0    98.1             3.0            3.0             4.0   \n",
       "5       410.0    149.0   119.7             5.0            3.0             5.0   \n",
       "6       250.0    124.0    96.0             5.0            4.0             5.0   \n",
       "\n",
       "   STAFFING_RATING  RN_STAFFING_RATING   AIDHRD   VOCHRD       ...        \\\n",
       "0              4.0                 4.0  3.43572  1.16495       ...         \n",
       "3              3.0                 3.0  2.32722  0.82104       ...         \n",
       "4              3.0                 2.0  2.33617  0.92407       ...         \n",
       "5              4.0                 3.0  2.57869  1.01443       ...         \n",
       "6              3.0                 4.0  1.99985  0.62768       ...         \n",
       "\n",
       "   ADJ_AIDE  ADJ_LPN   ADJ_RN  ADJ_TOTAL  INCIDENT_CNT  CMPLNT_CNT  FINE_CNT  \\\n",
       "0   3.11741  1.24750  0.83853    5.13047           0.0         0.0       0.0   \n",
       "3   2.40074  0.86962  0.56463    3.83026           0.0         1.0       0.0   \n",
       "4   2.55126  1.08955  0.30360    3.95709           0.0         0.0       0.0   \n",
       "5   2.56783  1.04823  0.46444    4.07866           0.0         1.0       0.0   \n",
       "6   2.12102  0.70311  0.75448    3.52979           1.0         1.0       0.0   \n",
       "\n",
       "   FINE_TOT  PAYDEN_CNT  TOT_PENLTY_CNT  \n",
       "0       0.0         0.0             0.0  \n",
       "3       0.0         0.0             0.0  \n",
       "4       0.0         0.0             0.0  \n",
       "5       0.0         0.0             0.0  \n",
       "6       0.0         0.0             0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the messy data and drop any rows with NAs\n",
    "df = df_raw.copy()\n",
    "df = df.select_dtypes([np.number])\n",
    "df.replace([\"NaN\", 'NaT'], np.nan, inplace = True)\n",
    "df = df.dropna(how='any', axis = 0)\n",
    "df.drop(columns=['ZIP', 'PHONE'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train & Test\n",
    "\n",
    "This assignment specified an 80/20 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test =  df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "The scaling for both train and test uses the train data to do the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns)\n",
    "X_train_scaled.drop(columns='OVERALL_RATING', inplace=True)\n",
    "y_train = train.reset_index().OVERALL_RATING\n",
    "\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "X_test_scaled.drop(columns='OVERALL_RATING', inplace=True)\n",
    "y_test = test.reset_index().OVERALL_RATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_SSA</th>\n",
       "      <th>BEDCERT</th>\n",
       "      <th>RESTOT</th>\n",
       "      <th>SURVEY_RATING</th>\n",
       "      <th>QUALITY_RATING</th>\n",
       "      <th>STAFFING_RATING</th>\n",
       "      <th>RN_STAFFING_RATING</th>\n",
       "      <th>AIDHRD</th>\n",
       "      <th>VOCHRD</th>\n",
       "      <th>RNHRD</th>\n",
       "      <th>...</th>\n",
       "      <th>ADJ_AIDE</th>\n",
       "      <th>ADJ_LPN</th>\n",
       "      <th>ADJ_RN</th>\n",
       "      <th>ADJ_TOTAL</th>\n",
       "      <th>INCIDENT_CNT</th>\n",
       "      <th>CMPLNT_CNT</th>\n",
       "      <th>FINE_CNT</th>\n",
       "      <th>FINE_TOT</th>\n",
       "      <th>PAYDEN_CNT</th>\n",
       "      <th>TOT_PENLTY_CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.368529</td>\n",
       "      <td>-0.840530</td>\n",
       "      <td>-0.678220</td>\n",
       "      <td>1.694526</td>\n",
       "      <td>0.826771</td>\n",
       "      <td>0.687788</td>\n",
       "      <td>0.488219</td>\n",
       "      <td>2.092472</td>\n",
       "      <td>0.788711</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.448243</td>\n",
       "      <td>1.075569</td>\n",
       "      <td>0.364616</td>\n",
       "      <td>1.492863</td>\n",
       "      <td>-0.379399</td>\n",
       "      <td>-0.569688</td>\n",
       "      <td>-0.561854</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.27574</td>\n",
       "      <td>-0.552266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114526</td>\n",
       "      <td>-0.260406</td>\n",
       "      <td>-0.148048</td>\n",
       "      <td>-0.637067</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.145120</td>\n",
       "      <td>-0.302080</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>-0.152219</td>\n",
       "      <td>-0.289842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166911</td>\n",
       "      <td>-0.027644</td>\n",
       "      <td>-0.264347</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>-0.379399</td>\n",
       "      <td>-0.437683</td>\n",
       "      <td>-0.561854</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.27574</td>\n",
       "      <td>-0.552266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114526</td>\n",
       "      <td>-0.078081</td>\n",
       "      <td>0.194783</td>\n",
       "      <td>0.140131</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.145120</td>\n",
       "      <td>-1.092378</td>\n",
       "      <td>0.070233</td>\n",
       "      <td>0.129669</td>\n",
       "      <td>-0.856345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436025</td>\n",
       "      <td>0.614437</td>\n",
       "      <td>-0.863757</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>-0.379399</td>\n",
       "      <td>-0.569688</td>\n",
       "      <td>-0.561854</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.27574</td>\n",
       "      <td>-0.552266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.684368</td>\n",
       "      <td>0.599437</td>\n",
       "      <td>0.140131</td>\n",
       "      <td>0.826771</td>\n",
       "      <td>0.687788</td>\n",
       "      <td>-0.302080</td>\n",
       "      <td>0.516264</td>\n",
       "      <td>0.376891</td>\n",
       "      <td>-0.509499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465651</td>\n",
       "      <td>0.493804</td>\n",
       "      <td>-0.494416</td>\n",
       "      <td>0.259319</td>\n",
       "      <td>-0.379399</td>\n",
       "      <td>-0.437683</td>\n",
       "      <td>-0.561854</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.27574</td>\n",
       "      <td>-0.552266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513673</td>\n",
       "      <td>0.269994</td>\n",
       "      <td>0.155442</td>\n",
       "      <td>0.917328</td>\n",
       "      <td>0.826771</td>\n",
       "      <td>-0.145120</td>\n",
       "      <td>0.488219</td>\n",
       "      <td>-0.548310</td>\n",
       "      <td>-0.681248</td>\n",
       "      <td>-0.143279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333199</td>\n",
       "      <td>-0.513767</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>-0.384385</td>\n",
       "      <td>-0.063247</td>\n",
       "      <td>-0.437683</td>\n",
       "      <td>-0.561854</td>\n",
       "      <td>-0.273495</td>\n",
       "      <td>-0.27574</td>\n",
       "      <td>-0.552266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNTY_SSA   BEDCERT    RESTOT  SURVEY_RATING  QUALITY_RATING  \\\n",
       "0   -0.368529 -0.840530 -0.678220       1.694526        0.826771   \n",
       "1   -0.114526 -0.260406 -0.148048      -0.637067        0.000141   \n",
       "2   -0.114526 -0.078081  0.194783       0.140131        0.000141   \n",
       "3    0.066905  0.684368  0.599437       0.140131        0.826771   \n",
       "4   -0.513673  0.269994  0.155442       0.917328        0.826771   \n",
       "\n",
       "   STAFFING_RATING  RN_STAFFING_RATING    AIDHRD    VOCHRD     RNHRD  \\\n",
       "0         0.687788            0.488219  2.092472  0.788711 -0.000448   \n",
       "1        -0.145120           -0.302080  0.053773 -0.152219 -0.289842   \n",
       "2        -0.145120           -1.092378  0.070233  0.129669 -0.856345   \n",
       "3         0.687788           -0.302080  0.516264  0.376891 -0.509499   \n",
       "4        -0.145120            0.488219 -0.548310 -0.681248 -0.143279   \n",
       "\n",
       "        ...        ADJ_AIDE   ADJ_LPN    ADJ_RN  ADJ_TOTAL  INCIDENT_CNT  \\\n",
       "0       ...        1.448243  1.075569  0.364616   1.492863     -0.379399   \n",
       "1       ...        0.166911 -0.027644 -0.264347  -0.032000     -0.379399   \n",
       "2       ...        0.436025  0.614437 -0.863757   0.116744     -0.379399   \n",
       "3       ...        0.465651  0.493804 -0.494416   0.259319     -0.379399   \n",
       "4       ...       -0.333199 -0.513767  0.171610  -0.384385     -0.063247   \n",
       "\n",
       "   CMPLNT_CNT  FINE_CNT  FINE_TOT  PAYDEN_CNT  TOT_PENLTY_CNT  \n",
       "0   -0.569688 -0.561854 -0.273495    -0.27574       -0.552266  \n",
       "1   -0.437683 -0.561854 -0.273495    -0.27574       -0.552266  \n",
       "2   -0.569688 -0.561854 -0.273495    -0.27574       -0.552266  \n",
       "3   -0.437683 -0.561854 -0.273495    -0.27574       -0.552266  \n",
       "4   -0.437683 -0.561854 -0.273495    -0.27574       -0.552266  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "logr = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = logr.predict(X_train_scaled)\n",
    "y_test_pred  = logr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.7\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[1035  303    1    0    0]\n",
      " [ 225 1737  359   32    0]\n",
      " [   1  757  284  887    0]\n",
      " [   0  382   11 1833  432]\n",
      " [   0    0    0   85 3333]]\n",
      "\n",
      "Train Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.82      0.77      0.80      1339\n",
      "        2.0       0.55      0.74      0.63      2353\n",
      "        3.0       0.43      0.15      0.22      1929\n",
      "        4.0       0.65      0.69      0.67      2658\n",
      "        5.0       0.89      0.98      0.93      3418\n",
      "\n",
      "avg / total       0.68      0.70      0.68     11697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\", round(logr.score(X_train_scaled, y_train),2))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.7\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[274  85   1   0   0]\n",
      " [ 61 402  76   6   0]\n",
      " [  0 192  71 201   0]\n",
      " [  0 108   0 452 100]\n",
      " [  0   0   0  20 811]]\n",
      "\n",
      "Test Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.82      0.76      0.79       360\n",
      "        2.0       0.51      0.74      0.60       545\n",
      "        3.0       0.48      0.15      0.23       464\n",
      "        4.0       0.67      0.68      0.68       660\n",
      "        5.0       0.89      0.98      0.93       831\n",
      "\n",
      "avg / total       0.69      0.70      0.68      2860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", round(logr.score(X_test_scaled, y_test),2))\n",
    "print(\"\\nTest Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic model on the scaled dataset with all the variables does pretty well. Total average accuracy is about 70%. The confusion matrix looks pretty good. The metrics from train to test don't change much which means the model is not dramatically over or under fitted. Any PCA regression needs to get pretty close to this score to be a good model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: PCA w. 2 components + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PCA object from sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit PCA object to 2 components \n",
    "pca_two = PCA(n_components=2)\n",
    "\n",
    "# use pca object to fit & apply pca transformation to data\n",
    "X_train_pca2 = pca_two.fit_transform(X_train_scaled)\n",
    "X_test_pca2  = pca_two.transform(X_test_scaled)\n",
    "\n",
    "# Train the logistic model on the PCA data\n",
    "logr_pca2 = LogisticRegression().fit(X_train_pca2, y_train)\n",
    "\n",
    "# Calculate predictions from trained model\n",
    "y_train_pca2_pred = logr_pca2.predict(X_train_pca2)\n",
    "y_test_pca2_pred  = logr_pca2.predict(X_test_pca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.38\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[ 459  708    6   42  124]\n",
      " [ 362 1066    5   83  837]\n",
      " [ 131  807    4   93  894]\n",
      " [  81  634    1  116 1826]\n",
      " [  31  452    1  110 2824]]\n",
      "\n",
      "Train Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.43      0.34      0.38      1339\n",
      "        2.0       0.29      0.45      0.35      2353\n",
      "        3.0       0.24      0.00      0.00      1929\n",
      "        4.0       0.26      0.04      0.07      2658\n",
      "        5.0       0.43      0.83      0.57      3418\n",
      "\n",
      "avg / total       0.33      0.38      0.30     11697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\", round(logr_pca2.score(X_train_pca2, y_train),2))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_pca2_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_pca2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.38\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[145 174   2  11  28]\n",
      " [ 81 252   0  23 189]\n",
      " [ 33 196   0  23 212]\n",
      " [ 15 169   0  15 461]\n",
      " [  5 121   1  24 680]]\n",
      "\n",
      "Test Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.52      0.40      0.45       360\n",
      "        2.0       0.28      0.46      0.35       545\n",
      "        3.0       0.00      0.00      0.00       464\n",
      "        4.0       0.16      0.02      0.04       660\n",
      "        5.0       0.43      0.82      0.57       831\n",
      "\n",
      "avg / total       0.28      0.38      0.30      2860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", round(logr_pca2.score(X_test_pca2, y_test),2))\n",
    "print(\"\\nTest Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_pca2_pred))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_pca2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only two components this model falls far short of the full model. The overall accuracy is only 38%, a little over half of the full score. The confusion matrix is all over the place whereas the non transformed model had lots of zeros on the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: PCA w. 16 components + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit PCA object to 2 components \n",
    "pca_16 = PCA(n_components=16)\n",
    "\n",
    "# use pca object to fit & apply pca transformation to data\n",
    "X_train_pca16 = pca_16.fit_transform(X_train_scaled)\n",
    "X_test_pca16  = pca_16.transform(X_test_scaled)\n",
    "\n",
    "# Build the logistic model on the scaled PCA data\n",
    "logr_pca16 = LogisticRegression().fit(X_train_pca16, y_train)\n",
    "\n",
    "# Calculate predictions from the model\n",
    "y_train_pca16_pred = logr_pca16.predict(X_train_pca16)\n",
    "y_test_pca16_pred  = logr_pca16.predict(X_test_pca16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.69\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[1032  306    1    0    0]\n",
      " [ 241 1718  361   33    0]\n",
      " [   1  770  262  896    0]\n",
      " [   0  386    3 1774  495]\n",
      " [   0    0    0   83 3335]]\n",
      "\n",
      "Train Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.81      0.77      0.79      1339\n",
      "        2.0       0.54      0.73      0.62      2353\n",
      "        3.0       0.42      0.14      0.21      1929\n",
      "        4.0       0.64      0.67      0.65      2658\n",
      "        5.0       0.87      0.98      0.92      3418\n",
      "\n",
      "avg / total       0.67      0.69      0.67     11697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score:\", round(logr_pca16.score(X_train_pca16, y_train),2))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_pca16_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_pca16_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.7\n",
      "\n",
      "Test Confusion Matrix\n",
      "[[272  88   0   0   0]\n",
      " [ 65 401  75   4   0]\n",
      " [  0 189  69 206   0]\n",
      " [  0 110   0 433 117]\n",
      " [  0   0   0  16 815]]\n",
      "\n",
      "Test Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.81      0.76      0.78       360\n",
      "        2.0       0.51      0.74      0.60       545\n",
      "        3.0       0.48      0.15      0.23       464\n",
      "        4.0       0.66      0.66      0.66       660\n",
      "        5.0       0.87      0.98      0.92       831\n",
      "\n",
      "avg / total       0.68      0.70      0.67      2860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", round(logr_pca16.score(X_test_pca16, y_test),2))\n",
    "print(\"\\nTest Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_pca16_pred))\n",
    "print(\"\\nTest Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_pca16_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great model! The stats are quite high and consistent from train to test. They are almost the same as the non-PCA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Model three, that is, the second PCA model with sixteen components performed the best. The scores were consistent between train and test, and the overall test score is the same as the non-transformed full model. It's amazing that model has the same accuracy with half the number of components as the original dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
