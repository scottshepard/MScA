{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics as skm\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing\n",
    "\n",
    "The data in this assignment comes from the UC Irvine Machine Learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header = None, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here doesn't have column names. They have to be added manually. The list of names comes from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education_num',\n",
    "    'marital_status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital_gain',\n",
    "    'capital_loss',\n",
    "    'hours_per_week',\n",
    "    'native_country',\n",
    "    'salary'\n",
    "]\n",
    "\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the dataframe and print out a few rows to confirm everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary column\n",
    "df.drop(columns='fnlwgt', inplace=True)\n",
    "\n",
    "# Revalue the target variable\n",
    "df.salary.replace({'<=50K':0, '>50K':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education_num      marital_status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   53           Private       11th              7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  salary  \n",
       "0             0              40  United-States       0  \n",
       "1             0              13  United-States       0  \n",
       "2             0              40  United-States       0  \n",
       "3             0              40  United-States       0  \n",
       "4             0              40           Cuba       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='salary')\n",
    "y = df.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 13)\n",
      "(32561,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 107)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22792, 107)\n",
      "(9769, 107)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=123)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Confusion Matrix\n",
      "[[6831  577]\n",
      " [ 955 1406]]\n",
      "\n",
      "Random Forest Test Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7408\n",
      "          1       0.71      0.60      0.65      2361\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "\n",
      "Random Forest Test ROC AUC\n",
      "0.870716422737007\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_test_rf_pred  = rf.predict(X_test)\n",
    "y_test_rf_proba = rf.predict_proba(X_test)\n",
    "\n",
    "print(\"Random Forest Test Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_rf_pred))\n",
    "print(\"\\nRandom Forest Test Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_rf_pred))\n",
    "print(\"\\nRandom Forest Test ROC AUC\")\n",
    "print(skm.roc_auc_score(y_test, y_test_rf_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Feature Importance')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11038c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = pd.DataFrame({'name': X_test.columns, 'importance': rf.feature_importances_})\n",
    "fi = fi.sort_values('importance', ascending=False).head(5)\n",
    "ax = fi.plot.bar(x='name', y='importance')\n",
    "ax.set_ylabel('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting \n",
    "\n",
    "Is there overfitting in this model? Random Forest is prone to overfitting. If the train accuracy and ROC AUC score are much higher than the test scores it is an indicator of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.97\n",
      "\n",
      "Train Confusion Matrix\n",
      "[[17102   210]\n",
      " [  478  5002]]\n",
      "\n",
      "Train Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     17312\n",
      "          1       0.96      0.91      0.94      5480\n",
      "\n",
      "avg / total       0.97      0.97      0.97     22792\n",
      "\n",
      "\n",
      "Train ROC AUC\n",
      "0.9958430115138901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_rf_pred  = rf.predict(X_train)\n",
    "y_train_rf_proba = rf.predict_proba(X_train)\n",
    "\n",
    "print(\"Train Score:\", round(rf.score(X_train, y_train), 2))\n",
    "print(\"\\nTrain Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_rf_pred))\n",
    "print(\"\\nTrain Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_rf_pred))\n",
    "print(\"\\nTrain ROC AUC\")\n",
    "print(skm.roc_auc_score(y_train, y_train_rf_proba[:,1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForest train score is much much higher than the test score. The train ROC is almost 1. The data has practically been memorized. There is definite overfitting happening in the RandomForest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AdaBoost Classifier - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.8min\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.2,0.4,0.6,0.8,1, 1.2],\n",
    "    'random_state' : [123]\n",
    "}\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "grid_search_abc = GridSearchCV(abc, parameters, cv=5, scoring='roc_auc',refit=True, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_best = grid_search_abc.best_estimator_\n",
    "\n",
    "y_test_abc_pred  = abc_best.predict(X_test)\n",
    "y_test_abc_proba = abc_best.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nAdaBoost Test Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_abc_pred))\n",
    "print(\"\\nAdaBoost Test Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_abc_pred))\n",
    "print(\"\\nAdaBoost Test ROC AUC\")\n",
    "print(skm.roc_auc_score(y_test, y_test_abc_proba[:,1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'name': X_test.columns, 'importance': abc_best.feature_importances_})\n",
    "fi = fi.sort_values('importance', ascending=False).head(5)\n",
    "ax = fi.plot.bar(x='name', y='importance')\n",
    "ax.set_ylabel('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting \n",
    "\n",
    "Is there overfitting in this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_abc_pred  = abc_best.predict(X_train)\n",
    "y_train_abc_proba = abc_best.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAdaBoost Train Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_abc_pred))\n",
    "print(\"\\nAdaBoost Train Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_abc_pred))\n",
    "print(\"\\nAdaBoost Train ROC AUC\")\n",
    "print(skm.roc_auc_score(y_train, y_train_abc_proba[:,1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly not! The slow learning method of boosting seems to have aleviated much of the problems regarding overfitting. The train AUC and precision are almost exactly the same as test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gradient Boosting Classifier - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.2,0.6,1.0],\n",
    "    'max_depth': [1,2],\n",
    "    'random_state' : [123]\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "grid_search_gbc = GridSearchCV(gbc, parameters, cv=5, scoring='roc_auc',refit=True, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_best = grid_search_gbc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_gbc_pred  = gbc_best.predict(X_test)\n",
    "y_test_gbc_proba = gbc_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting Test Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_test, y_test_gbc_pred))\n",
    "print(\"\\nGradient Boosting Test Classification Report\")\n",
    "print(skm.classification_report(y_test, y_test_gbc_pred))\n",
    "print(\"\\nGradient Boosting Test ROC AUC\")\n",
    "print(skm.roc_auc_score(y_test, y_test_gbc_proba[:,1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'name': X_test.columns, 'importance': gbc_best.feature_importances_})\n",
    "fi = fi.sort_values('importance', ascending=False).head(5)\n",
    "ax = fi.plot.bar(x='name', y='importance')\n",
    "ax.set_ylabel('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Is there overfitting with this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_gbc_pred  = gbc_best.predict(X_train)\n",
    "y_train_gbc_proba = gbc_best.predict_proba(X_train)\n",
    "\n",
    "print(\"Gradient Boosting Train Confusion Matrix\")\n",
    "print(skm.confusion_matrix(y_train, y_train_gbc_pred))\n",
    "print(\"\\nnGradient Boosting Train Classification Report\")\n",
    "print(skm.classification_report(y_train, y_train_gbc_pred))\n",
    "print(\"\\nnGradient Boosting Train ROC AUC\")\n",
    "print(skm.roc_auc_score(y_train, y_train_gbc_proba[:,1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, no! The boosting algorthims do not seem to lead to overfitting the way that RandomForest does. This is a significant improvment over that ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual Problems: \n",
    "\n",
    "**5) What does the alpha parameter represent in AdaBoost? Please refer to chapter 7 of the Hands-On ML book if you are struggling.**\n",
    "\n",
    "The alpha paramter in AdaBoost is the weight of that an individual predictor contributes to the ensemble model. The more accurate the predictor is the higher the weight it will get. The predictor weight is based on accuracy of the simple model, and also on the learning rate. A low learning rate will lead to a slower convergence on accuracy and more overall predictors with each predictor contributing less to the ensemble.\n",
    "\n",
    "**6) In AdaBoost explain how the final predicted class is determined. Be sure to reference the alpha term in your explanation.**\n",
    "\n",
    "Once all the predictors are trained and predictor weights determined, the model is ready to determine classes. It does this by running the test data through all the predictors in the model. Each weak learner outputs a class and the classes are weighted by the predictor weight, the alpha parameter. The class with a weighted majority wins.\n",
    "\n",
    "**7) In Gradient Boosting, what is the role of the max_depth parameter? Why is it important to tune on this parameter?**\n",
    "\n",
    "The max_depth parameter is the depth of the individual trees. Generally the lower the better. The point of boosting is to combine the results of many weak learners to produce a strong learner. Trees with only a few nodes are weak and are only marginally better than random guessing. This is good for a boosting algorithm. Choosing the number of splits in the individual trees controls the amount of learning we allow from those trees. With a greater depth you probably need fewer trees in your algorithm, so it is a parameter that controls the rate of learning. Will your algorithm learn very slowly or very quickly? With a larger number of splits you can learn more quickly which might be preferred on a large dataset even if you sacrifice some accuracy.\n",
    "\n",
    "**8) In Part (e) of Steps 2-4 you determined the top 5 predictors across each model. Do any predictors show up in the top 5 predictors for all three models? If so, comment on if this predictor makes sense given what you are attempting to predict. (Note: If you don't have any predictors showing up across all 3 predictors, explain one that shows up in 2 of them).**\n",
    "\n",
    "Many of the same variables show up as top 5 predictors in all three models. Age is one that stands out to me. This makes sense because older people tend to make more. They have worked more years at their jobs and have amassed more industry knowledge. They have progress further up the corporate ladder. It makes complete sense that this would be a top predictor of salary.\n",
    "\n",
    "**9) From the models run in steps 2-4, which performs the best based on the Classification Report? Support your reasoning with evidence from your test data and be sure to share the optimal hyperparameters found from your grid search.**\n",
    "\n",
    "Gradient Boosting performed the best of all the models run. It significantly outperformed RandomForest, achieiving an 87% test precision and a 92.8 test AUC ROC score. It only marginally outperformed AdaBoost to the point that I would say those two models tied. Both AdaBoost and Gradient Boosting had very high AUC ROC scores, very high precision, and low difference between train and test. However Gradient has a very very small advantage over AdaBoost on this dataset.\n",
    "\n",
    "**10) For your best performing model, plot out an ROC curve. Feel free to use sklearn, matplotlib or any other method in python.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = skm.roc_curve(y_test, y_test_gbc_proba[:,1])\n",
    "roc_auc = skm.auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "ax.plot(fpr, tpr)\n",
    "plt.title('ROC Curve')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
