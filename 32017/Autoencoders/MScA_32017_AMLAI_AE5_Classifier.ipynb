{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning and Artificial Intelligence (MScA 32017)\n",
    "\n",
    "# Project: Anomalies Detection using Autoencoders\n",
    "\n",
    "## Notebook 5: Compare Autoencoder with Classifier\n",
    "\n",
    "## Yuri Balasanov, Andrey Kobyshev, &copy; iLykei 2018\n",
    "\n",
    "This notebook compares anomalies detection by autoencoder and by classifier trained on one type of attack. Then both are tried on a different type of attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "The main goal of this notebook is to show that autoencoder is a more universal method for anomaly detection than classifier because autoencoder is trained on data without anomalies, thus it can detect rare deviations from normal regardless of their type.\n",
    "\n",
    "Unlike classifier autoencoder solution does not require labels for training, some limited number of labels may be useful only for validation. This means that autoencoder solution does not get affected by imbalanced classes, which is a typical challenge for classification of anomalies as rare events.\n",
    "\n",
    "For comparison this notebook shows how to build a classifier - a neural network that is trained with labels to distinguish normal and anomaly classes (attack of type \"ipsweep\").\n",
    "\n",
    "Dataset is the same as in <a href=\"https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb\" target=\"_blank\">MScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb</a> \n",
    "\n",
    "After training and testing classifier on one type of attack the same classifier will be checked on a different type of attack. For both classes of attack classifier will need to be compared with the autoencoder solution. Complete this comparison when autoencoder model is trained and saved to file.\n",
    "\n",
    "Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model, load_model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support,\n",
    "                             cohen_kappa_score, accuracy_score)\n",
    "import sklearn.metrics as skm\n",
    "from pylab import rcParams\n",
    "import pickle\n",
    "\n",
    "# Set some visualization parameters:\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 8\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Read train dataset `kddCupTrain.csv` from `kddCupData.zip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddCupTrain = pd.read_csv('kddCupTrain.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and prepare the data as described in <a href=\"https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb\" target=\"_blank\">MScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb</a>, **except: do not separate the \"normal\" instances from the training dataset. A model will be fit to the entire dataset**.  \n",
    "\n",
    "Note that the features list should be exactly the same as it was for an Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skiped code\n",
    "#Prepare the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all transformations and preparations the dataset should have format as follows:\n",
    "\n",
    "`print(kddCupTrain.head(2))`  \n",
    "\n",
    "`'       0         4         5        6         8         9        10  \\\n",
    "0 -0.16002 -0.011000 -0.081782 -0.00281 -0.002293 -0.052638 -0.007482   \n",
    "1 -0.16002 -0.012928 -0.092466 -0.00281 -0.002293 -0.052638 -0.007482   `\n",
    "\n",
    "`'       11        12        13        14        15        16        17  \\\n",
    "0  0.638870 -0.004254 -0.017549 -0.010038 -0.007049 -0.021138 -0.018912   \n",
    "1 -1.565263 -0.004254 -0.017549 -0.010038 -0.007049 -0.021138 -0.018912   `\n",
    "\n",
    "`'       18        20        21        22        23        24        25  \\\n",
    "0 -0.063614 -0.001502 -0.061903  0.165707  0.000046 -0.054189 -0.065417   \n",
    "1 -0.063614 -0.001502 -0.061903 -0.399884 -0.459251 -0.054189 -0.065417   `\n",
    "\n",
    "`'       26        27        28        29        30        31        32  \\\n",
    "0 -0.244655 -0.247066  0.157689 -0.156892 -0.486813 -0.285323  0.612755   \n",
    "1  4.115563  4.137151  0.157689 -0.156892 -0.486813 -1.400495  0.612755   `\n",
    "\n",
    "`'       33       34        35        36        37        38        39  \\\n",
    "0  0.504939 -0.31261 -0.456592 -0.249604 -0.070939  0.590035 -0.257053   \n",
    "1  0.504939 -0.31261  2.893958  0.327044 -0.070939 -0.067872  4.180321   `\n",
    "\n",
    "`'       40    1_icmp     1_tcp     1_udp     2_IRC     2_X11    2_auth  \\\n",
    "0 -0.255692 -0.159083  0.529347 -0.490912 -0.023004 -0.011634 -0.048641   \n",
    "1  4.251843 -0.159083  0.529347 -0.490912 -0.023004 -0.011634 -0.048641   `\n",
    "\n",
    "`'    2_ctf  2_domain  2_domain_u   2_eco_i   2_ecr_i  2_finger    2_ftp  \\\n",
    "0 -0.003679 -0.006882    -0.24971 -0.125649 -0.059192 -0.071618 -0.06236   \n",
    "1 -0.003679 -0.006882    -0.24971 -0.125649 -0.059192 -0.071618 -0.06236   `\n",
    "\n",
    "`' 2_ftp_data  2_gopher   2_http   2_imap4    2_link     2_mtp    2_name  \\\n",
    "0   -0.200526 -0.003679  0.76902 -0.001839 -0.003829 -0.003522 -0.003829   \n",
    "1   -0.200526 -0.003679  0.76902 -0.001839 -0.003829 -0.003522 -0.003829   `\n",
    "\n",
    "`'  2_ntp_u   2_other   2_pop_3  2_private   2_red_i  2_remote_job     2_rje  \\\n",
    "0 -0.062415 -0.246557 -0.030349  -0.286053 -0.003186     -0.003522 -0.003679   \n",
    "1 -0.062415 -0.246557 -0.030349  -0.286053 -0.003186     -0.003522 -0.003679`\n",
    "\n",
    "`'  2_shell    2_smtp     2_ssh  2_telnet  2_tftp_u  2_tim_i    2_time  \\\n",
    "0 -0.002375 -0.327462 -0.004749 -0.047641 -0.001839 -0.00281 -0.023248   \n",
    "1 -0.002375 -0.327462 -0.004749 -0.047641 -0.001839 -0.00281 -0.023248`   \n",
    "\n",
    "`' 2_urh_i   2_urp_i   2_whois     3_OTH     3_REJ    3_RSTO    3_RSTR  \\\n",
    "0 -0.01234 -0.074221 -0.003358 -0.003679 -0.241512 -0.025561 -0.018488   \n",
    "1 -0.01234 -0.074221 -0.003358 -0.003679  4.140580 -0.025561 -0.018488`\n",
    "\n",
    "`'     3_S0      3_S1      3_S2    3_S3      3_SF      3_SH  Class  \n",
    "0 -0.020706 -0.022906 -0.012476 -0.0068  0.246491 -0.001062      0  \n",
    "1 -0.020706 -0.022906 -0.012476 -0.0068 -4.056951 -0.001062      0`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prepared data to the file:\n",
    "\n",
    "# pickle.dump(kddCupTrain, open('./Saved_Files/prepared_kddCupTrain.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared data from the file:\n",
    "\n",
    "kddCupTrain = pickle.load(open('./Saved_Files/prepared_kddCupTrain.sav', 'rb'))\n",
    "featuresList = [col for col in kddCupTrain if col != 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Classifier\n",
    "\n",
    "Input layer of the classifier has the same shape as the Autoencoder.  \n",
    "The output layer has single unit. \n",
    "\n",
    "Select number and dimentions of hidden layers. The model should not be too complex. One or two hidden layers is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "\n",
    "# Build a Model 'classModel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and validation subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(kddCupTrain, \n",
    "                               test_size=0.2, \n",
    "                               shuffle=True, \n",
    "                               stratify=kddCupTrain['Class'],\n",
    "                               random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model using following arguments of function `fit()`:\n",
    "\n",
    "`x = train[featuresList],\n",
    "y = train['Class'],\n",
    "validation_data=(test[featuresList], test['Class'])`  \n",
    "\n",
    "Use ModelCheckpoint to save the best model to file.  \n",
    "\n",
    "Experiment with parameters like: `epochs`, `batch_size`, `callbacks`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 256\n",
    "adam = Adam(lr=0.0005)\n",
    "classModel.compile(optimizer=adam, \n",
    "                    loss='mean_squared_error')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=1, verbose=0)\n",
    "checkpointer = ModelCheckpoint(filepath=\"./Saved_Files/classifier.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "class_history = classModel.fit(x=train[featuresList], y=train['Class'],\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test[featuresList], test['Class']),\n",
    "                    verbose=1,\n",
    "                    callbacks=[earlystopping, checkpointer]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classifier\n",
    "\n",
    "Load the model saved by `ModelCheckpoint`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedClassifier = load_model('./Saved_Files/classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the fitting history:\n",
    "plt.plot(class_history['loss'])\n",
    "plt.plot(class_history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this model make prediction for the validation dataset:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testProb = fittedClassifier.predict(test[featuresList])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret `testProb` as confidence in detection of attacks.  \n",
    "Create a dataframe with \"predicted probabilities\" and \"true class\" columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testProb = testProb[:,0]\n",
    "class_prob_df = pd.DataFrame({'probabilities': testProb,\n",
    "                        'true_class': test['Class']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the ROC curve and calculate AUC value in the same way as in [FMScA_32017_AMLAI_AE3_FraudDetection.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE3_FraudDetection.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fclassifier_validation_ROC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted probabilities of normal and attack classes (see [FMScA_32017_AMLAI_AE3_FraudDetection.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE3_FraudDetection.ipynb) for example of graph).  \n",
    "\n",
    "Select a threshold for predicting class from probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fclassifier_validation_prob.png)\n",
    "\n",
    "Plot the confusion matrix for the selected threshold (see [FMScA_32017_AMLAI_AE3_FraudDetection.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE3_FraudDetection.ipynb) for example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fclassifier_validation_confusion.png)\n",
    "\n",
    "Calculate Accuracy and Cohen's Kappa (like in [FMScA_32017_AMLAI_AE3_FraudDetection.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE3_FraudDetection.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cohen's Kappa =  0.9673961327246483\n",
    "Accuracy =  0.9991767551748831`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the quality of the trained classifier for detecting attack of type \"ipsweep\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Classifier and the Autoencoder on Validation Data\n",
    "\n",
    "Load the trained Autoencoder Model that has been saved in section 2.2. of [MScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedAutoencoder = load_model('./Saved_Files/autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct the validation dataset, calculate the mean squared error of the reconstruction ([FMScA_32017_AMLAI_AE3_FraudDetection.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE3_FraudDetection.ipynb)).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aePredictions = fittedAutoencoder.predict(test[featuresList])\n",
    "mse = skm.mean_squared_error(test[featuresList].transpose(),\n",
    "                             aePredictions.transpose(),\n",
    "                             multioutput='raw_values')\n",
    "ae_error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': test['Class']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a ROC curve for the reconstruction error and the labels of the `test` dataset.  \n",
    "Calculate AUC value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fautoencoder_validation_ROC.png)\n",
    "\n",
    "Select a high level quantile of the MSE sample as a threshold for the attack detection.  \n",
    "Plot the reconstruction error for different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fautoencoder_validation_error.png)\n",
    "\n",
    "Plot the confusion matrix for the selected threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2Fautoencoder_validation_confusion.png)  \n",
    "\n",
    "Calculate Accuracy and Cohen's Kappa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cohen's Kappa =  0.44632002116032854\n",
    "Accuracy =  0.9702391357057069`\n",
    "\n",
    "Note that classifier gives better results on the validation dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare both methods using new test data containing another type of anomaly: \"portsweep\".  \n",
    "\n",
    "# Read and Transform Test Dataset with Different Class of Attack\n",
    "\n",
    "Read test dataset from file ['kddCup_TestForClassifier.csv'](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FkddCup_TestForClassifier.zip) and check it for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddCupTest = pd.read_csv('kddCup_TestForClassifier.csv', header=None)\n",
    "print(\"Shape of kddCupTest: \",kddCupTest.shape)\n",
    "print(\"There are any missing values: \", kddCupTest.isnull().values.any())\n",
    "print(kddCupTest.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kddCupTest` contains labels, so it is possible to compare quality of predictions by different models.  \n",
    "\n",
    "The label column (**\"41\"**) contains 0 for \"normal\" connections and 1 for attacks.  \n",
    "Rename column **\"41\"** to **\"Class\"**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddCupTest.rename(columns={41:'Class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the test data like in [MScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FAnomalies%20Detection%2FMScA_32017_AMLAI_AE4_kddCup_Instructions.ipynb).\n",
    "\n",
    "Note that this time there is label column in the test dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all transformations `kddCupTest` should have exactly same columns list as `kddCupTrain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared data from the file:\n",
    "\n",
    "kddCupTest = pickle.load(open('./Saved_Files/prepared_kddCupTest.sav', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Classifier and Autoencoder\n",
    "\n",
    "Make predictions for `kddCupTest` using `fittedClassifier` and `fittedAutoencoder`.\n",
    "\n",
    "Calculate AUC for both models and construct plots of AUC. errors and confusion table as was done for the validation dataset. \n",
    "\n",
    "Use same thresholds as selected for the validation data. \n",
    "Calculate Accuracy and Cohen's Kappa for both models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction using fittedClassifier\n",
    "\n",
    "testProb = fittedClassifier.predict(kddCupTest[featuresList])\n",
    "testProb = testProb[:,0]\n",
    "new_class_prob_df = pd.DataFrame({'probabilities': testProb,\n",
    "                        'true_class': kddCupTest['Class']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the ROC curve and calculate AUC for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](classifier_test_ROC.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted probabilities of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](classifier_test_prob.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix for the threshold selected for the training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](classifier_test_confusion.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Accuracy and Cohen's Kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:  \n",
    "`Cohen's Kappa =  0.04288617959306329\n",
    "Accuracy =  0.9894789324270699`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct the test dataset using `fittedAutoencoder`, calculate the mean squared error of the reconstruction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aePredictions = fittedAutoencoder.predict(kddCupTest[featuresList])\n",
    "mse = skm.mean_squared_error(kddCupTest[featuresList].transpose(),\n",
    "                             aePredictions.transpose(),\n",
    "                             multioutput='raw_values')\n",
    "new_ae_error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': kddCupTest['Class']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct ROC curve and calculate AUC for the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](autoencoder_test_ROC.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot reconstruction error for different classes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](autoencoder_test_error.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix for the threshold selected for the training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](autoencoder_test_confusion.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Accuracy and Cohen's Kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder:  \n",
    "`Cohen's Kappa =  0.3826631619160502\n",
    "Accuracy =  0.9686301244416406`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the Classifier is worse on another type of attack. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
