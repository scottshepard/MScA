{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '~/Datasets/32018/'\n",
    "#file = 'jeep.txt'\n",
    "file = 'webhose_cat.pkl'\n",
    "path = directory + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawled</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-30T18:28:45.012+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Avery Dennison's (AVY) Q4 results are likely t...</td>\n",
       "      <td>IRobot downgraded to neutral from buy at Sidot...</td>\n",
       "      <td>http://omgili.com/ri/.wHSUbtEfZQRfU.5KUm1RkeXy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-30T18:29:07.001+02:00</td>\n",
       "      <td>french</td>\n",
       "      <td>1m95, c’est trop grand. Et sa stature, Bertran...</td>\n",
       "      <td>\"Bertrand Zibi Abeghe, encore prisonnier, et t...</td>\n",
       "      <td>http://omgili.com/ri/.wHSUbtEfZTpzFtnXyQJIwJ.j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-30T18:29:40.000+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "      <td>http://omgili.com/ri/jHIAmI4hxg.zDiulpymXqU_n4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-30T18:30:05.007+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Currently adding the following games:\\n100 (by...</td>\n",
       "      <td></td>\n",
       "      <td>http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-30T18:30:05.013+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "      <td></td>\n",
       "      <td>http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         crawled language  \\\n",
       "0  2018-01-30T18:28:45.012+02:00  english   \n",
       "1  2018-01-30T18:29:07.001+02:00   french   \n",
       "2  2018-01-30T18:29:40.000+02:00  english   \n",
       "3  2018-01-30T18:30:05.007+02:00  english   \n",
       "4  2018-01-30T18:30:05.013+02:00  english   \n",
       "\n",
       "                                                text  \\\n",
       "0  Avery Dennison's (AVY) Q4 results are likely t...   \n",
       "1  1m95, c’est trop grand. Et sa stature, Bertran...   \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...   \n",
       "3  Currently adding the following games:\\n100 (by...   \n",
       "4  Quote: : » Currently adding the following game...   \n",
       "\n",
       "                                               title  \\\n",
       "0  IRobot downgraded to neutral from buy at Sidot...   \n",
       "1  \"Bertrand Zibi Abeghe, encore prisonnier, et t...   \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  \n",
       "0  http://omgili.com/ri/.wHSUbtEfZQRfU.5KUm1RkeXy...  \n",
       "1  http://omgili.com/ri/.wHSUbtEfZTpzFtnXyQJIwJ.j...  \n",
       "2  http://omgili.com/ri/jHIAmI4hxg.zDiulpymXqU_n4...  \n",
       "3  http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...  \n",
       "4  http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.language=='english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].map(lambda x: re.sub('[^a-zA-Z0-9 @ . , : - _]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Dennison's (AVY) Q4 results are likely t...</td>\n",
       "      <td>Avery Dennisons AVY Q4 results are likely to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently adding the following games:\\n100 (by...</td>\n",
       "      <td>Currently adding the following games:100 by ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "      <td>Quote: :  Currently adding the following games...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "      <td>Quote: :  Currently adding the following games...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Avery Dennison's (AVY) Q4 results are likely t...   \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...   \n",
       "3  Currently adding the following games:\\n100 (by...   \n",
       "4  Quote: : » Currently adding the following game...   \n",
       "5  Quote: : » Currently adding the following game...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Avery Dennisons AVY Q4 results are likely to g...  \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...  \n",
       "3  Currently adding the following games:100 by ev...  \n",
       "4  Quote: :  Currently adding the following games...  \n",
       "5  Quote: :  Currently adding the following games...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'text_clean']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sshepa74/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_clean = [clean(doc).split() for doc in df.text_clean.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(news_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 ms, sys: 3.23 ms, total: 37.7 ms\n",
      "Wall time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time doc_term_matrix = [dictionary.doc2bow(doc) for doc in news_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 601 ms, total: 12 s\n",
      "Wall time: 13.3 s\n",
      "CPU times: user 15.2 s, sys: 1.15 s, total: 16.4 s\n",
      "Wall time: 14.6 s\n",
      "CPU times: user 17 s, sys: 1.47 s, total: 18.5 s\n",
      "Wall time: 12.1 s\n",
      "CPU times: user 17.5 s, sys: 1.53 s, total: 19 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%time ldamodel3 = LdaMulticore(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "%time ldamodel5 = LdaMulticore(doc_term_matrix, num_topics=5, id2word = dictionary, passes=50)\n",
    "%time ldamodel7 = LdaMulticore(doc_term_matrix, num_topics=7, id2word = dictionary, passes=50)\n",
    "%time ldamodel9 = LdaMulticore(doc_term_matrix, num_topics=9, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.009*\"tax\" + 0.008*\"u\" + 0.008*\"jan\" + 0.007*\"company\" + 0.006*\"share\"')\n",
      "(1, '0.016*\"market\" + 0.009*\"plant\" + 0.006*\"case\" + 0.005*\"industry\" + 0.005*\"product\"')\n",
      "(2, '0.007*\"city\" + 0.007*\"median\" + 0.006*\"estimate\" + 0.006*\"university\" + 0.006*\"2017\"')\n",
      "\n",
      "(0, '0.011*\"plant\" + 0.007*\"case\" + 0.007*\"city\" + 0.006*\"median\" + 0.006*\"estimate\"')\n",
      "(1, '0.016*\"caterpillar\" + 0.011*\"company\" + 0.011*\"share\" + 0.008*\"stock\" + 0.007*\"product\"')\n",
      "(2, '0.014*\"inc\" + 0.009*\"jan\" + 0.006*\"bucket\" + 0.005*\"corp\" + 0.005*\"dec\"')\n",
      "(3, '0.008*\"company\" + 0.007*\"iot\" + 0.006*\"new\" + 0.005*\"health\" + 0.004*\"mnubo\"')\n",
      "(4, '0.015*\"market\" + 0.011*\"tax\" + 0.009*\"u\" + 0.006*\"jan\" + 0.006*\"company\"')\n",
      "\n",
      "(0, '0.007*\"new\" + 0.006*\"company\" + 0.006*\"house\" + 0.006*\"market\" + 0.005*\"system\"')\n",
      "(1, '0.018*\"plant\" + 0.012*\"caterpillar\" + 0.011*\"case\" + 0.009*\"share\" + 0.008*\"company\"')\n",
      "(2, '0.021*\"sphere\" + 0.020*\"amazon\" + 0.019*\"seattle\" + 0.011*\"monday\" + 0.011*\"grand\"')\n",
      "(3, '0.016*\"tax\" + 0.012*\"u\" + 0.007*\"company\" + 0.007*\"china\" + 0.006*\"repatriation\"')\n",
      "(4, '0.007*\"2\" + 0.005*\"canna\" + 0.004*\"caterpillar\" + 0.004*\"post\" + 0.004*\"space\"')\n",
      "(5, '0.044*\"market\" + 0.012*\"report\" + 0.012*\"industry\" + 0.009*\"analysis\" + 0.008*\"growth\"')\n",
      "(6, '0.012*\"jan\" + 0.008*\"inc\" + 0.008*\"median\" + 0.008*\"2017\" + 0.008*\"city\"')\n",
      "\n",
      "(0, '0.013*\"city\" + 0.012*\"median\" + 0.011*\"estimate\" + 0.010*\"university\" + 0.010*\"2017\"')\n",
      "(1, '0.015*\"tax\" + 0.012*\"u\" + 0.010*\"company\" + 0.008*\"china\" + 0.006*\"repatriation\"')\n",
      "(2, '0.020*\"inc\" + 0.013*\"jan\" + 0.008*\"corp\" + 0.007*\"dec\" + 0.006*\"nov\"')\n",
      "(3, '0.011*\"et\" + 0.010*\"robot\" + 0.010*\"2018\" + 0.010*\"jan\" + 0.007*\"year\"')\n",
      "(4, '0.018*\"plant\" + 0.013*\"case\" + 0.006*\"wardian\" + 0.006*\"terrarium\" + 0.006*\"blade\"')\n",
      "(5, '0.011*\"biopolymer\" + 0.011*\"coating\" + 0.007*\"post\" + 0.006*\"canna\" + 0.005*\"caterpillar\"')\n",
      "(6, '0.034*\"market\" + 0.015*\"caterpillar\" + 0.012*\"share\" + 0.012*\"report\" + 0.011*\"company\"')\n",
      "(7, '0.010*\"autonomous\" + 0.009*\"truck\" + 0.007*\"haul\" + 0.007*\"rio\" + 0.004*\"employee\"')\n",
      "(8, '0.019*\"sphere\" + 0.018*\"amazon\" + 0.017*\"seattle\" + 0.010*\"2018\" + 0.010*\"monday\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel3.print_topics(num_topics=3, num_words=5), sep='\\n')\n",
    "print()\n",
    "print(*ldamodel5.print_topics(num_topics=5, num_words=5), sep='\\n')\n",
    "print()\n",
    "print(*ldamodel7.print_topics(num_topics=7, num_words=5), sep='\\n')\n",
    "print()\n",
    "print(*ldamodel9.print_topics(num_topics=9, num_words=5), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
