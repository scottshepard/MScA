{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1 - Regular Expressions\n",
    "\n",
    "**Prompt:**  \n",
    "Improve your analysis from Week-1 by identifying specific tokens (words / keywords) that lead to failed food inspections in Chicago leveraging tokenization, stemming and lemmatization in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/rowena/Datasets/\"\n",
    "file_path = data_path + \"Food_Inspections.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df[df.Results == 'Fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = df[~df.Violations.isna()].Violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 115.0517008304596 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tokens_list = []\n",
    "for violation in violations:\n",
    "    tokens_list.append(nltk.tokenize.word_tokenize(violation))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [item for sublist in tokens_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.Series(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".           650312\n",
       ",           571337\n",
       "AND         384597\n",
       ":           333666\n",
       "Comments    204355\n",
       "-           204023\n",
       "THE         192357\n",
       "IN          169887\n",
       "|           168857\n",
       "TO          158674\n",
       "OF          158052\n",
       "CLEAN       121782\n",
       "FOOD        117387\n",
       "MUST         99527\n",
       "and          94122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rather unhelpful list of top words found in failed inspection violation notices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = pd.Series([wnl.lemmatize(t.lower()) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".          650312\n",
       ",          571337\n",
       "and        478733\n",
       ":          333666\n",
       "the        245091\n",
       "in         208795\n",
       "comment    204406\n",
       "-          204023\n",
       "of         200590\n",
       "to         180682\n",
       "|          168857\n",
       "food       166544\n",
       "clean      133866\n",
       "all        118732\n",
       "must       108764\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_vc = lemmas.value_counts()\n",
    "lemma_vc.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not that helpful. Hopefully POS tags can weed out the punctuation and whatnot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_df = pd.DataFrame(lemma_vc).reset_index().rename(columns={'index':'lemma', 0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.736386060714722 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pos_tags = nltk.pos_tag(lemma_df.lemma, tagset='universal')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_df['pos'] = pd.Series(pos_tags).apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>650312</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>571337</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>478733</td>\n",
       "      <td>CONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "      <td>333666</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>245091</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lemma   count   pos\n",
       "0     .  650312     .\n",
       "1     ,  571337     .\n",
       "2   and  478733  CONJ\n",
       "3     :  333666     .\n",
       "4   the  245091   DET"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comment</td>\n",
       "      <td>204406</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>|</td>\n",
       "      <td>168857</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>food</td>\n",
       "      <td>166544</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>must</td>\n",
       "      <td>108764</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>area</td>\n",
       "      <td>106865</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>equipment</td>\n",
       "      <td>92825</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>be</td>\n",
       "      <td>89084</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>floor</td>\n",
       "      <td>88086</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>repair</td>\n",
       "      <td>81589</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>maintained</td>\n",
       "      <td>73322</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sink</td>\n",
       "      <td>68265</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>wall</td>\n",
       "      <td>65146</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>constructed</td>\n",
       "      <td>61043</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prep</td>\n",
       "      <td>59033</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cleaning</td>\n",
       "      <td>58840</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>storage</td>\n",
       "      <td>55574</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>shall</td>\n",
       "      <td>55483</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>observed</td>\n",
       "      <td>54722</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>maintain</td>\n",
       "      <td>53588</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>violation</td>\n",
       "      <td>52239</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>surface</td>\n",
       "      <td>49194</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>room</td>\n",
       "      <td>46734</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>code</td>\n",
       "      <td>46299</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cooler</td>\n",
       "      <td>44944</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>installed</td>\n",
       "      <td>44732</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lemma   count   pos\n",
       "6       comment  204406  NOUN\n",
       "10            |  168857  VERB\n",
       "11         food  166544  NOUN\n",
       "14         must  108764  VERB\n",
       "15         area  106865  NOUN\n",
       "18    equipment   92825  NOUN\n",
       "19           be   89084  VERB\n",
       "21        floor   88086  NOUN\n",
       "22       repair   81589  NOUN\n",
       "23   maintained   73322  VERB\n",
       "25         sink   68265  NOUN\n",
       "26         wall   65146  NOUN\n",
       "27  constructed   61043  VERB\n",
       "29         prep   59033  NOUN\n",
       "31     cleaning   58840  VERB\n",
       "34      storage   55574  VERB\n",
       "35        shall   55483  VERB\n",
       "36     observed   54722  VERB\n",
       "37     maintain   53588  NOUN\n",
       "38    violation   52239  NOUN\n",
       "42      surface   49194  NOUN\n",
       "44         room   46734  NOUN\n",
       "45         code   46299  NOUN\n",
       "46       cooler   44944  NOUN\n",
       "47    installed   44732  VERB"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df[(lemma_df.pos=='NOUN') | (lemma_df.pos=='VERB')].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a somewhat useufl list now. Most of the irrevelant or nonsense words have been weeded out. \n",
    "\n",
    "\"Comments\" is from the structure of data. It's included anytime there is additional information. Same deal with the pipe symbol. It's interesting that pos_tag picked that up as a verg.\n",
    "\n",
    "Top words on a failed food inspection include the words \"food\". That makes sense. \"Must\" is probably from comments like \"INSTRUCTED MANAGER TO PROVIDE AND MAINTAIN A WORKING LONG STEM THERMOMETER TO CHECK FOOD ITEMS IN HOT HOLDING. MUST COMPLY OR CITATIONS WILL BE ISSUED.\" We see other words like \"equipment\", \"maintain\", \"contructed\" and \"installed\". This is probably referring to pieces of kitchen gear. Places in the building are also common like \"floor\", \"sink\", and \"wall\". Structural problems can lead to a failed inspection. I'm kind of surprised that \"violation\" isn't higher on the list."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
