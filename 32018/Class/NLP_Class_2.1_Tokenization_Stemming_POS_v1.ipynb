{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 1 Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Stemming & Lemmatization, Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --user textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 12:04:33) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flu', 'season', 'hitting', 'earlier', ',', 'with', 'dozens', 'more', 'outbreaks', '—', 'and', 'more', 'severe', 'symptoms']\n"
     ]
    }
   ],
   "source": [
    "text = \"Flu season hitting earlier, with dozens more outbreaks — and more severe symptoms\"\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/rowena/Datasets/32018 NLP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = '3boat10.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7778 samples and 79620 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5702),\n",
       " ('the', 3338),\n",
       " ('and', 3215),\n",
       " ('.', 3081),\n",
       " ('to', 1748),\n",
       " ('a', 1621),\n",
       " ('of', 1425),\n",
       " ('I', 1208),\n",
       " ('it', 1159),\n",
       " ('in', 931)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(directory+book)\n",
    "bk_3boat = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent clean words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6232 samples and 29826 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 378),\n",
       " ('would', 362),\n",
       " ('harris', 316),\n",
       " ('george', 308),\n",
       " ('one', 246),\n",
       " ('us', 228),\n",
       " ('boat', 186),\n",
       " ('get', 179),\n",
       " ('could', 175),\n",
       " ('got', 163)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have to instantiate a Text object first, and then call it on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = Text(nltk.corpus.gutenberg.words(directory+book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A concordance view shows us every occurrence of a given word, together with some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 199 matches:\n",
      "                                     BOAT ( TO SAY NOTHING OF THE DOG ). Three\n",
      "                                     Boat by Jerome K . Jerome CHAPTER I . THR\n",
      "ty of people very bad indeed , whole boat - loads of them ; but I never met a \n",
      " like a fellow I saw on the Yarmouth boat one day , I could account for the se\n",
      "ckles I ever tasted in a respectable boat . Did you have any ?\" For myself , I\n",
      "eep , you get fooling about with the boat , and slop me overboard . If you ask\n",
      "o down in the morning , and take the boat up to Chertsey , and George , who wo\n",
      "n stillness . Then we run our little boat into some quiet nook , and the tent \n",
      "talk , the river , playing round the boat , prattles strange old tales and sec\n",
      "is a good two inches of water in the boat , and all the things are damp . You \n",
      "rd man , who has been baling out the boat , and who has spilled the water down\n",
      "uld not allow of the navigation of a boat sufficiently large to take the thing\n",
      "eople , on that voyage , load up the boat till it is ever in danger of swampin\n",
      " ! Throw it overboard . It makes the boat so heavy to pull , you nearly faint \n",
      "row the lumber over , man ! Let your boat of life be light , packed with only \n",
      " dangerous thing . You will find the boat easier to pull then , and it will no\n",
      " suggested George ; \" we will have a boat with a cover . It is ever so much si\n",
      "ean . You fix iron hoops up over the boat , and stretch a huge canvas over the\n",
      " stem to stern , and it converts the boat into a sort of little house , and it\n",
      "it was so pleasant to wake up in the boat in the fresh morning , and plunge in\n",
      "ave Harris clean and fresh about the boat , even if we did have to take a few \n",
      "ooze . We kept it in the nose of the boat , and , from there , it oozed down t\n",
      " the rudder , impregnating the whole boat and everything in it on its way , an\n",
      "away from it at Marlow . We left the boat by the bridge , and took a walk thro\n",
      "r to take paraffine oil with us in a boat again - except , of course , in case\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 31 matches:\n",
      "                                      DOG ). Three Men in a Boat by Jerome K . \n",
      "ed up at me , and think : \" Oh , that dog will never live . He will be snatched\n",
      "t door but one for having a ferocious dog at large , that had kept him pinned u\n",
      "e and someone to love you , a cat , a dog , and a pipe or two , enough to eat a\n",
      "ed him . I didn ' t encourage him . A dog like that don ' t want any encouragem\n",
      " with eggs and bacon , irritating the dog , or flirting with the slavey , inste\n",
      "dly . He would take bronchitis in the dog - days , and have hay - fever at Chri\n",
      "by the lady of the house ? That china dog that ornaments the bedroom of my furn\n",
      "my furnished lodgings . It is a white dog . Its eyes blue . Its nose is a delic\n",
      "me it is more than probable that that dog will be dug up from somewhere or othe\n",
      "s age , do not see the beauty of that dog . We are too familiar with it . It is\n",
      "o our eyes . So it is with that china dog . In 2288 people will gush over it . \n",
      " one another , and we beamed upon the dog , too . We loved each other , we love\n",
      "INE TO DRINK THE RIVER . - A PEACEFUL DOG . - STRANGE DISAPPEARANCE OF HARRIS A\n",
      "life , with care . I do not blame the dog ( contenting myself , as a rule , wit\n",
      "but mangy about the middle ; a bull - dog , a few Lowther Arcade sort of animal\n",
      "chained up there , between the bull - dog and the poodle . He sat and looked ab\n",
      "d dignified . He looked at the bull - dog , sleeping dreamlessly on his right .\n",
      "his own place , and caught the bull - dog by the ear , and tried to throw him a\n",
      "ed to throw him away ; and the bull - dog , a curiously impartial animal , went\n",
      "d , and snatched up that sweet little dog of hers ( he had laid the tyke up for\n",
      "have chilled the heart of the boldest dog . He stopped abruptly , and looked ba\n",
      "' s boy , with basket . Long - haired dog . Cheesemonger ' s boy , with basket \n",
      "owards us on the sluggish current , a dog . It was one of the quietest and peac\n",
      "dogs I have ever seen . I never met a dog who seemed more contented - more easy\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"similar\" helps us discover what other words appear in a similar range of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river man thing time water night day bank lock way morning things boy\n",
      "room matter world air city business kettle\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit man long morning change dream body widow party trout boat harris\n",
      "hundred rest week river mean he out is\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course them thing water whisky dogs three boat to the george harris\n",
      "one that us view it him some months\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"beer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional information helps determine the location of a word in the text: how many words from the beginning it appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ccce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textList.dispersion_plot([\"boat\", \"dog\", \"river\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default tokenization includes all surrounting punctuation charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can invoke RegexpTokenizer to eliminate punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68364"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will match any word characters until it reaches a non-word character, like a space\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(bk_3boat)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring lexical diversity: dividing unique words by overall words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09222146948327893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(textList)) / len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_diversity_pct(text):\n",
    "    return (len(set(textList)) / len(textList))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.222146948327893"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_diversity_pct(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normatliation with stemming and lemmatization\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "    am, are, is =>  be\n",
    "    dog, dogs, dog's, dogs' => dog\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "    the girl's dogs are different breeds => the girl dog be differ breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three',\n",
       " 'men',\n",
       " 'boat',\n",
       " 'say',\n",
       " 'nothing',\n",
       " 'dog',\n",
       " 'three',\n",
       " 'men',\n",
       " 'boat',\n",
       " 'jerome',\n",
       " 'jerome',\n",
       " 'chapter',\n",
       " 'three',\n",
       " 'invalids',\n",
       " 'sufferings',\n",
       " 'george',\n",
       " 'harris',\n",
       " 'victim',\n",
       " 'one',\n",
       " 'hundred']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting lists to strings to simplify displaying / visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l = (words[0:50])\n",
    "words_s = ', '.join(words_l)\n",
    "type (words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three, men, boat, say, nothing, dog, three, men, boat, jerome, jerome, chapter, three, invalids, sufferings, george, harris, victim, one, hundred, seven, fatal, maladies, useful, prescriptions, cure, liver, complaint, children, agree, overworked, need, rest, week, rolling, deep, george, suggests, river, montmorency, lodges, objection, original, motion, carried, majority, three, one, four, us'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or using \"print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapter', 'three', 'invalid', 'suffer', 'georg', 'harri', 'victim', 'one', 'hundr', 'seven', 'fatal', 'maladi', 'use', 'prescript', 'cure', 'liver', 'complaint', 'children', 'agre', 'overwork', 'need', 'rest', 'week', 'roll', 'deep', 'georg', 'suggest', 'river', 'montmor', 'lodg', 'object', 'origin', 'motion', 'carri', 'major', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapt', 'three', 'invalid', 'suff', 'georg', 'har', 'victim', 'on', 'hundr', 'sev', 'fat', 'malady', 'us', 'prescrib', 'cur', 'liv', 'complaint', 'childr', 'agr', 'overwork', 'nee', 'rest', 'week', 'rol', 'deep', 'georg', 'suggest', 'riv', 'montm', 'lodg', 'object', 'origin', 'mot', 'carry', 'maj', 'three', 'on', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
    "\n",
    "The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. The dictionary checking makes lemmatizers significantly slower than stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u']\n"
     ]
    }
   ],
   "source": [
    "print([wnl.lemmatize(t) for t in words[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use help function to get explanations of endividual tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = \"The University of Chicago is a private research university in Chicago, Illinois\"\n",
    "uc2 = \"It is one of the world's leading and most influential institutions of higher learning, with top-ten positions in numerous rankings and measures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d962c747bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinfo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nltk.pos_tag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc1)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all possible tags and values\n",
    "#nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from URL\n",
    "#### BeautifulSoup to clean up meta-tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/University_of_Chicago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing employees of the University of Chicago Medical Center)[4]Students16,446Undergraduates6,286[5]Postgraduates10,159[5]LocationChicago, Illinois, United StatesCampusUrban217 acres (87.8 ha) (Main Campus)[6]42 acres (17.0 ha) (Warren Woods Ecological Field Station, Warren Woods State Park)[7]30 acres (12.1 ha) (Yerkes Observatory)ColorsMaroon and White[8]         NicknameMaroonsSporting affiliationsNCAA Division III – UAAMascotPhil the PhoenixWebsitewww.uchicago.edu\n",
      "The University of Chicago (UChicago, U of C, or Chicago) is a private research university in Chicago, Illinois. Founded in 1890 by John D. Rockefeller, the school is located on a 217-acre campus in Chicago's Hyde Park neighborhood, near Lake Michigan.[9] The University of Chicago holds top-ten positions in various national and international rankings.[10][11][12][13][14]\n",
      "The university is composed of an undergraduate college as well as various graduate programs and interdisciplinary committees organized into five academic research divisions. Beyond the arts and sciences, Chicago is also well known for its professional schools, which include the Pritzker School of Medicine, the Booth School of Business, the Law School, the School of Social Service Administration, the Harris School \n"
     ]
    }
   ],
   "source": [
    "uc_wiki = (soup.get_text())\n",
    "#print (type(uc_wiki))\n",
    "print (uc_wiki[6740:8000]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after BeautifulSoup we are left with a lot of garbade - mostly punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presidential', 'library', 'and', 'offices', 'of', 'the', 'Obama', 'Foundation', '.', '[', '23', ']', 'The', 'University', 'of', 'Chicago', 'has', 'produced', 'many', 'prominent', 'alumni', ',', 'faculty', 'members', 'and', 'researchers', '.', 'As', 'of', '2018', ',', '98', 'Nobel', 'laureates', '[', '24', ']', 'have', 'been', 'affiliated', 'with', 'the', 'university', 'as', 'professors', ',', 'students', ',', 'faculty', ',', 'or', 'staff', ',', 'making', 'it', 'a', 'university', 'with', 'one', 'of', 'the', 'highest', 'concentrations', 'of', 'Nobel', 'laureates', 'in', 'the', 'world', '.', 'Similarly', ',', '34', 'faculty', 'members', 'and', '18', 'alumni', 'have', 'been', 'awarded', 'the', 'MacArthur', '``', 'Genius', 'Grant', \"''\", '.', '[', '25', ']', 'In', 'addition', ',', 'Chicago', \"'s\", 'alumni', 'and', 'faculty', 'include']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_tokens = nltk.tokenize.word_tokenize(uc_wiki)\n",
    "uc_wiki_tokens_uncleaned = uc_wiki_tokens\n",
    "print (uc_wiki_tokens[2000:2100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chicago', 311),\n",
       " ('University', 304),\n",
       " ('The', 180),\n",
       " ('Retrieved', 140),\n",
       " ('university', 117),\n",
       " ('School', 72),\n",
       " ('College', 58),\n",
       " ('In', 47),\n",
       " ('September', 41),\n",
       " ('Archived', 38)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if len(word) > 1]\n",
    "\n",
    "# Remove punctuation\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if word.isalpha()]\n",
    "\n",
    "# Remove stopwords\n",
    "uc_wiki_tokens_no_stopwords = [word for word in uc_wiki_tokens if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(uc_wiki_tokens_no_stopwords)\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of our cleaned web scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'Chicago', 'Wikipedia', 'function', 'wgCanonicalNamespace', 'wgCanonicalSpecialPageName', 'false', 'wgNamespaceNumber', 'wgPageName', 'wgTitle', 'University', 'Chicago', 'wgCurRevisionId', 'wgRevisionId', 'wgArticleId', 'wgIsArticle', 'true', 'wgIsRedirect', 'false', 'wgAction', 'view', 'wgUserName', 'null', 'wgUserGroups', 'wgCategories', 'Pages', 'URL', 'errors', 'maint', 'Archived', 'copy', 'title', 'Webarchive', 'template', 'wayback', 'links', 'All', 'articles', 'dead', 'external', 'links', 'Articles', 'dead', 'external', 'links', 'July', 'Articles', 'permanently', 'dead', 'external', 'links', 'Articles', 'short', 'description', 'Use', 'mdy', 'dates', 'March', 'Good', 'articles', 'Articles', 'containing', 'text', 'Pages', 'using', 'infobox', 'university', 'image', 'name', 'parameter', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'May', 'All', 'articles', 'containing', 'potentially', 'dated', 'statements', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'Commons', 'category', 'link', 'Wikidata', 'Coordinates', 'Wikidata', 'Wikipedia', 'articles']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords = nltk.Text(uc_wiki_tokens_no_stopwords)\n",
    "print (uc_wiki_text_no_stopwords[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', 'Wikipedia', 'function', 'wgCanonicalNamespace', 'wgCanonicalSpecialPageName', 'false', 'wgNamespaceNumber', 'wgPageName', 'wgTitle', 'University', 'of', 'Chicago', 'wgCurRevisionId', 'wgRevisionId', 'wgArticleId', 'wgIsArticle', 'true', 'wgIsRedirect', 'false', 'wgAction', 'view', 'wgUserName', 'null', 'wgUserGroups', 'wgCategories', 'Pages', 'with', 'URL', 'errors', 'maint', 'Archived', 'copy', 'as', 'title', 'Webarchive', 'template', 'wayback', 'links', 'All', 'articles', 'with', 'dead', 'external', 'links', 'Articles', 'with', 'dead', 'external', 'links', 'from', 'July', 'Articles', 'with', 'permanently', 'dead', 'external', 'links', 'Articles', 'with', 'short', 'description', 'Use', 'mdy', 'dates', 'from', 'March', 'Good', 'articles', 'Articles', 'containing', 'text', 'Pages', 'using', 'infobox', 'university', 'with', 'the', 'image', 'name', 'parameter', 'Articles', 'containing', 'potentially', 'dated', 'statements', 'from', 'May', 'All', 'articles', 'containing', 'potentially', 'dated', 'statements', 'Articles', 'containing', 'potentially', 'dated', 'statements']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned = nltk.Text(uc_wiki_tokens)\n",
    "print (uc_wiki_text_cleaned[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', '-', 'Wikipedia', 'document.documentElement.className', '=', 'document.documentElement.className.replace', '(', '/', '(', '^|\\\\s', ')', 'client-nojs', '(', '\\\\s|', '$', ')', '/', ',', '``', '$', '1client-js', '$', '2', \"''\", ')', ';', '(', 'window.RLQ=window.RLQ||', '[', ']', ')', '.push', '(', 'function', '(', ')', '{', 'mw.config.set', '(', '{', '``', 'wgCanonicalNamespace', \"''\", ':', \"''\", \"''\", ',', \"''\", 'wgCanonicalSpecialPageName', \"''\", ':', 'false', ',', \"''\", 'wgNamespaceNumber', \"''\", ':0', ',', \"''\", 'wgPageName', \"''\", ':', \"''\", 'University_of_Chicago', \"''\", ',', \"''\", 'wgTitle', \"''\", ':', \"''\", 'University', 'of', 'Chicago', \"''\", ',', \"''\", 'wgCurRevisionId', \"''\", ':891875765', ',', \"''\", 'wgRevisionId', \"''\", ':891875765', ',', \"''\", 'wgArticleId', \"''\", ':32127', ',', \"''\", 'wgIsArticle', \"''\", ':', 'true', ',', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw = nltk.Text(uc_wiki_tokens_uncleaned)\n",
    "print (uc_wiki_text_raw[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying simlarity function - which option produces best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicago site illinois college the campus uchicago addition history\n",
      "reputation buildings classes report economist maroon retrieved isbn\n",
      "kind spurs mo\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation andl noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college school office faculty chicago campus world first history board\n",
      "as the site law development department one buildings president\n",
      "professor\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college school office faculty chicago campus world first president\n",
      "board as the site law development department one history buildings\n",
      "professor\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging our web page with POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order for the tagger to be effective, it has to tag each word based on the word itself, as well as its context within a sentence. \n",
    "Depending on your corpus, certain taggers perform better the others.  Like with SPSS TA dictionaries, you can start with pre-trained POS Tagger and then try multiple different options to see which one will perform best for you.\n",
    "You can also customize and train your own taggers to match your particular corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_wiki_tagged = nltk.pos_tag(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('function', 'NN'),\n",
       " ('wgCanonicalNamespace', 'NN'),\n",
       " ('wgCanonicalSpecialPageName', 'NN'),\n",
       " ('false', 'JJ'),\n",
       " ('wgNamespaceNumber', 'NN'),\n",
       " ('wgPageName', 'NN')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_wiki_tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring alternative text analysis packages: TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('document.documentElement.className', 'NN'),\n",
       " ('=', 'NNP'),\n",
       " ('document.documentElement.className.replace', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('^|\\\\s', 'NNP'),\n",
       " ('client-nojs', 'NN')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process  cleaned-up version from NLTK we will have to convert text from nltk.text.Text to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "words_list = (uc_wiki_text_cleaned[0:])\n",
    "words_string = ', '.join(words_l)\n",
    "print(type(words_list))\n",
    "print(type(words_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(words_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('three', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('boat', 'NN'),\n",
       " ('say', 'VBP'),\n",
       " ('nothing', 'NN'),\n",
       " ('dog', 'NN'),\n",
       " ('three', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('boat', 'NN'),\n",
       " ('jerome', 'NN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be careful with embedded functions to pluralize and singularize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = TextBlob(words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three', 'invalids', 'sufferings']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'invalid', 'suffering'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[12:15].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men', 'boat']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['threes', 'mens', 'boats'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:3].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:20].lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_words = blob.words\n",
    "print (b_words[1020:1040])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sentences = blob.sentences\n",
    "print (b_sentences[10:15])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
