{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance (a.k.a. Levenshtein Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('commuter', 'computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('Computer', 'computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('acorn', 'corn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('aacorn', 'corn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('soup', 'potato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago 1\n",
      "university 9\n",
      "composed 7\n",
      "undergraduate 12\n",
      "college 5\n",
      "various 7\n",
      "graduate 7\n",
      "programs 7\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'chicago'\n",
    "\n",
    "word_n = ['Chicago', 'university', 'composed', 'undergraduate', 'college', 'various',  'graduate', 'programs']\n",
    " \n",
    "for word in word_n:\n",
    "    editDistance = nltk.edit_distance(word_1, word)\n",
    "    print(word, editDistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit distance between sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Edit Distance between sent1 and sent2\n",
      "12 Edit Distance between sent1 and sent3\n",
      "9 Edit Distance between sent1 and sent4\n",
      "9 Edit Distance between sent1 and sent5\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"I love cookies\"\n",
    "sent2 = \"i love cookies\"\n",
    "sent3 = \"cookies I love\"\n",
    "sent4 = \"I love cookies with tea\"\n",
    "sent5 = \"I love tea with cookies\"\n",
    "\n",
    "ed_sent_1_2 = nltk.edit_distance(sent1, sent2)\n",
    "ed_sent_1_3 = nltk.edit_distance(sent1, sent3)\n",
    "ed_sent_1_4 = nltk.edit_distance(sent1, sent4)\n",
    "ed_sent_1_5 = nltk.edit_distance(sent1, sent5)\n",
    "\n",
    "print(ed_sent_1_2, 'Edit Distance between sent1 and sent2')\n",
    "print(ed_sent_1_3, 'Edit Distance between sent1 and sent3')\n",
    "print(ed_sent_1_4, 'Edit Distance between sent1 and sent4')\n",
    "print(ed_sent_1_5, 'Edit Distance between sent1 and sent5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Edit Distance, you cannot just run Jaccard Distance on the strings directly; you must first convert them to the set type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Distance between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.jaccard_distance(set('commuter'), set('computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.jaccard_distance(set('Commuter'), set('computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.jaccard_distance(set('acorn'), set('corn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.jaccard_distance(set('aacorn'), set('corn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.jaccard_distance(set('soup'), set('potato'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago 0.14285714285714285\n",
      "university 0.9285714285714286\n",
      "composed 0.8181818181818182\n",
      "undergraduate 0.8333333333333334\n",
      "college 0.625\n",
      "various 0.7\n",
      "graduate 0.8181818181818182\n",
      "programs 0.7\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'chicago'\n",
    "\n",
    "word_n = ['Chicago', 'university', 'composed', 'undergraduate', 'college', 'various',  'graduate', 'programs']\n",
    " \n",
    "for word in word_n:\n",
    "    jaccardDistance = nltk.jaccard_distance(set(word_1), set(word))\n",
    "    print(word, jaccardDistance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard distance between sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 Jaccard Distance between sent1 and sent2\n",
      "0.0 Jaccard Distance between sent1 and sent3\n",
      "0.2857142857142857 Jaccard Distance between sent1 and sent4\n",
      "0.2857142857142857 Jaccard Distance between sent1 and sent5\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"I love cookies\"\n",
    "sent2 = \"i love cookies\"\n",
    "sent3 = \"cookies I love\"\n",
    "sent4 = \"I love cookies with tea\"\n",
    "sent5 = \"I love tea with cookies\"\n",
    "\n",
    "jd_sent_1_2 = nltk.jaccard_distance(set(sent1), set(sent2))\n",
    "jd_sent_1_3 = nltk.jaccard_distance(set(sent1), set(sent3))\n",
    "jd_sent_1_4 = nltk.jaccard_distance(set(sent1), set(sent4))\n",
    "jd_sent_1_5 = nltk.jaccard_distance(set(sent1), set(sent5))\n",
    "\n",
    "print(jd_sent_1_2, 'Jaccard Distance between sent1 and sent2')\n",
    "print(jd_sent_1_3, 'Jaccard Distance between sent1 and sent3')\n",
    "print(jd_sent_1_4, 'Jaccard Distance between sent1 and sent4')\n",
    "print(jd_sent_1_5, 'Jaccard Distance between sent1 and sent5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Book and distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C://Users//IBM_ADMIN//Documents//Teaching//Data Projects//Text//Books//'\n",
    "book = '3boat10.txt'\n",
    "\n",
    "f = open(directory+book)\n",
    "book_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(book_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'one', 'or', 'two', 'diseases', 'each', 'So', 'I', 'went', 'straight', 'up', 'and', 'saw', 'him', 'and', 'he', 'said', 'Well', 'what', \"'s\", 'the', 'matter', 'with', 'you', 'I', 'said', 'I', 'will', 'not', 'take', 'up', 'your', 'time', 'dear', 'boy', 'with', 'telling', 'you', 'what', 'is', 'the', 'matter', 'with', 'me', 'Life', 'is', 'brief', 'and', 'you', 'might', 'pass', 'away', 'before', 'I', 'had', 'finished', 'But', 'I', 'will', 'tell']\n"
     ]
    }
   ],
   "source": [
    "b_words = blob.words\n",
    "print (b_words[1020:1080])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67696\n"
     ]
    }
   ],
   "source": [
    "lenWords = len(b_words)\n",
    "print(lenWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"- \n",
      "MONTMORENCY LODGES AN OBJECTION.\"), Sentence(\"- ORIGINAL MOTION CARRIED BY MAJORITY OF \n",
      "THREE TO ONE.\"), Sentence(\"THERE were four of us - George, and William Samuel Harris, and myself, \n",
      "and Montmorency.\"), Sentence(\"We were sitting in my room, smoking, and talking about \n",
      "how bad we were - bad from a medical point of view I mean, of course.\"), Sentence(\"We were all feeling seedy, and we were getting quite nervous about it.\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob.sentences\n",
    "print (b_sentences[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507\n"
     ]
    }
   ],
   "source": [
    "lenSentences = len(b_sentences)\n",
    "print(lenSentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining prior, next and current words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee, islice, chain\n",
    "\n",
    "def previous_and_next(some_iterable):\n",
    "    prevs, items, nexts = tee(some_iterable, 3)\n",
    "    prevs = chain([None], prevs)\n",
    "    nexts = chain(islice(nexts, 1, None), [None])\n",
    "    return zip(prevs, items, nexts)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item is now THREE next is MEN previous is None\n",
      "Item is now MEN next is IN previous is THREE\n",
      "Item is now IN next is A previous is MEN\n",
      "Item is now A next is BOAT previous is IN\n",
      "Item is now BOAT next is TO previous is A\n",
      "Item is now TO next is SAY previous is BOAT\n",
      "Item is now SAY next is NOTHING previous is TO\n",
      "Item is now NOTHING next is OF previous is SAY\n",
      "Item is now OF next is THE previous is NOTHING\n",
      "Item is now THE next is DOG previous is OF\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for previous, item, nxt in previous_and_next(b_words):\n",
    "    print (\"Item is now\", item, \"next is\", nxt, \"previous is\", previous)\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit distance betwen current and next words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance between:  THREE &  MEN is:  4\n",
      "Edit Distance between:  MEN &  IN is:  2\n",
      "Edit Distance between:  IN &  A is:  2\n",
      "Edit Distance between:  A &  BOAT is:  3\n",
      "Edit Distance between:  BOAT &  TO is:  3\n",
      "Edit Distance between:  TO &  SAY is:  3\n",
      "Edit Distance between:  SAY &  NOTHING is:  7\n",
      "Edit Distance between:  NOTHING &  OF is:  6\n",
      "Edit Distance between:  OF &  THE is:  3\n",
      "Edit Distance between:  THE &  DOG is:  3\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for previous, item, nxt in previous_and_next(b_words):\n",
    "    print (\"Edit Distance between: \", item, \"& \", nxt, \"is: \", nltk.edit_distance(item,nxt))\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard distance betwen current and next words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Distance between:  THREE &  MEN is:  0.8333333333333334\n",
      "Jaccard Distance between:  MEN &  IN is:  0.75\n",
      "Jaccard Distance between:  IN &  A is:  1.0\n",
      "Jaccard Distance between:  A &  BOAT is:  0.75\n",
      "Jaccard Distance between:  BOAT &  TO is:  0.5\n",
      "Jaccard Distance between:  TO &  SAY is:  1.0\n",
      "Jaccard Distance between:  SAY &  NOTHING is:  1.0\n",
      "Jaccard Distance between:  NOTHING &  OF is:  0.8571428571428571\n",
      "Jaccard Distance between:  OF &  THE is:  1.0\n",
      "Jaccard Distance between:  THE &  DOG is:  1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for previous, item, nxt in previous_and_next(b_words):\n",
    "    print (\"Jaccard Distance between: \", item, \"& \", nxt, \"is: \", nltk.jaccard_distance(set(item),set(nxt)))\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit distance betwen current and next sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance between:  THREE MEN IN A BOAT\n",
      "(TO SAY NOTHING OF THE DOG). &  Three Men in a Boat by Jerome K. Jerome\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. is:  45\n",
      "Edit Distance between:  Three Men in a Boat by Jerome K. Jerome\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. &  THREE INVALIDS. is:  51\n",
      "Edit Distance between:  THREE INVALIDS. &  - SUFFERINGS OF GEORGE AND HARRIS. is:  26\n",
      "Edit Distance between:  - SUFFERINGS OF GEORGE AND HARRIS. &  - A VICTIM TO ONE \n",
      "HUNDRED AND SEVEN FATAL MALADIES. is:  36\n",
      "Edit Distance between:  - A VICTIM TO ONE \n",
      "HUNDRED AND SEVEN FATAL MALADIES. &  - USEFUL PRESCRIPTIONS. is:  43\n",
      "Edit Distance between:  - USEFUL PRESCRIPTIONS. &  - CURE FOR \n",
      "LIVER COMPLAINT IN CHILDREN. is:  28\n",
      "Edit Distance between:  - CURE FOR \n",
      "LIVER COMPLAINT IN CHILDREN. &  - WE AGREE THAT WE ARE OVERWORKED, AND NEED \n",
      "REST. is:  37\n",
      "Edit Distance between:  - WE AGREE THAT WE ARE OVERWORKED, AND NEED \n",
      "REST. &  - A WEEK ON THE ROLLING DEEP? is:  35\n",
      "Edit Distance between:  - A WEEK ON THE ROLLING DEEP? &  - GEORGE SUGGESTS THE RIVER. is:  24\n",
      "Edit Distance between:  - GEORGE SUGGESTS THE RIVER. &  - \n",
      "MONTMORENCY LODGES AN OBJECTION. is:  24\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for previous, item, nxt in previous_and_next(b_sentences):\n",
    "    print (\"Edit Distance between: \", item, \"& \", nxt, \"is: \", nltk.edit_distance(item,nxt))\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard distance betwen current and next sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Distance between:  THREE MEN IN A BOAT\n",
      "(TO SAY NOTHING OF THE DOG). &  Three Men in a Boat by Jerome K. Jerome\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. is:  0.6857142857142857\n",
      "Jaccard Distance between:  Three Men in a Boat by Jerome K. Jerome\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I. &  THREE INVALIDS. is:  0.7419354838709677\n",
      "Jaccard Distance between:  THREE INVALIDS. &  - SUFFERINGS OF GEORGE AND HARRIS. is:  0.4444444444444444\n",
      "Jaccard Distance between:  - SUFFERINGS OF GEORGE AND HARRIS. &  - A VICTIM TO ONE \n",
      "HUNDRED AND SEVEN FATAL MALADIES. is:  0.3333333333333333\n",
      "Jaccard Distance between:  - A VICTIM TO ONE \n",
      "HUNDRED AND SEVEN FATAL MALADIES. &  - USEFUL PRESCRIPTIONS. is:  0.3333333333333333\n",
      "Jaccard Distance between:  - USEFUL PRESCRIPTIONS. &  - CURE FOR \n",
      "LIVER COMPLAINT IN CHILDREN. is:  0.3333333333333333\n",
      "Jaccard Distance between:  - CURE FOR \n",
      "LIVER COMPLAINT IN CHILDREN. &  - WE AGREE THAT WE ARE OVERWORKED, AND NEED \n",
      "REST. is:  0.48\n",
      "Jaccard Distance between:  - WE AGREE THAT WE ARE OVERWORKED, AND NEED \n",
      "REST. &  - A WEEK ON THE ROLLING DEEP? is:  0.4090909090909091\n",
      "Jaccard Distance between:  - A WEEK ON THE ROLLING DEEP? &  - GEORGE SUGGESTS THE RIVER. is:  0.5714285714285714\n",
      "Jaccard Distance between:  - GEORGE SUGGESTS THE RIVER. &  - \n",
      "MONTMORENCY LODGES AN OBJECTION. is:  0.5652173913043478\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for previous, item, nxt in previous_and_next(b_sentences):\n",
    "    print (\"Jaccard Distance between: \", item, \"& \", nxt, \"is: \", nltk.jaccard_distance(set(item),set(nxt)))\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Grams and Tokenization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaching Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C://Users//IBM_ADMIN//Documents//Teaching//Data Projects//Text//Books//'\n",
    "\n",
    "#book = 'Book_2.txt'\n",
    "book = '3boat10.txt'\n",
    "#book_short = '3boat10_short.txt'\n",
    "#book_out = '3boat10_out.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3607),\n",
       " ('and', 3395),\n",
       " ('to', 1790),\n",
       " ('a', 1714),\n",
       " ('of', 1496),\n",
       " ('it', 1422),\n",
       " ('i', 1213),\n",
       " ('in', 977),\n",
       " ('that', 950),\n",
       " ('he', 920)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the N most common words in book\n",
    "top_N = 10\n",
    "\n",
    "words = re.findall(r'\\w+', open(directory+book, encoding=\"utf8\").read().lower())\n",
    "# \\w -- matches a \"word\" character: a letter or digit or underbar [a-zA-Z0-9_].\n",
    "# + pattern must appear at least once. \n",
    "\n",
    "word_freq = Counter(words).most_common(top_N)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>3395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency\n",
       "Word           \n",
       "the        3607\n",
       "and        3395\n",
       "to         1790\n",
       "a          1714\n",
       "of         1496\n",
       "it         1422\n",
       "i          1213\n",
       "in          977\n",
       "that        950\n",
       "he          920"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = Counter(words).most_common()\n",
    "\n",
    "word_freq_df = pd.DataFrame(word_freq,\n",
    "                    columns=['Word', 'Frequency']).set_index('Word')\n",
    "\n",
    "word_freq_df.sort_values('Frequency', ascending=False, inplace=True)\n",
    "\n",
    "word_freq_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6579, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7773 samples and 79641 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5702),\n",
       " ('the', 3338),\n",
       " ('and', 3215),\n",
       " ('.', 3081),\n",
       " ('to', 1748),\n",
       " ('a', 1621),\n",
       " ('of', 1425),\n",
       " ('I', 1208),\n",
       " ('it', 1159),\n",
       " ('in', 931)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(directory+book, encoding=\"utf8\")\n",
    "raw = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK also has embedded RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flu',\n",
       " 'season',\n",
       " 'hitting',\n",
       " 'earlier',\n",
       " 'with',\n",
       " 'dozens',\n",
       " 'more',\n",
       " 'outbreaks',\n",
       " 'and',\n",
       " 'more',\n",
       " 'severe',\n",
       " 'symptoms']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(\"Flu season hitting earlier, with dozens more outbreaks â€” and more severe symptoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>5702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>3338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Frequency\n",
       "0    ,       5702\n",
       "1  the       3338\n",
       "2  and       3215\n",
       "3    .       3081\n",
       "4   to       1748\n",
       "5    a       1621\n",
       "6   of       1425\n",
       "7    I       1208\n",
       "8   it       1159\n",
       "9   in        931"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df = pd.DataFrame(fdist.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning-up tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6240 samples and 29842 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 378),\n",
       " ('would', 362),\n",
       " ('harris', 316),\n",
       " ('george', 308),\n",
       " ('one', 246),\n",
       " ('us', 228),\n",
       " ('boat', 186),\n",
       " ('get', 179),\n",
       " ('could', 175),\n",
       " ('got', 163)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harris</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>george</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>us</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boat</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>get</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>could</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>got</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Frequency\n",
       "0    said        378\n",
       "1   would        362\n",
       "2  harris        316\n",
       "3  george        308\n",
       "4     one        246\n",
       "5      us        228\n",
       "6    boat        186\n",
       "7     get        179\n",
       "8   could        175\n",
       "9     got        163"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df = pd.DataFrame(fdist.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Grams\n",
    "### Basic N-Gramming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('quick', 'brown', 'fox')\n",
      "('brown', 'fox', 'jumps')\n",
      "('fox', 'jumps', 'over')\n",
      "('jumps', 'over', 'the')\n",
      "('over', 'the', 'lazy')\n",
      "('the', 'lazy', 'dog')\n"
     ]
    }
   ],
   "source": [
    "sentence = 'quick brown fox jumps over the lazy dog'\n",
    "n = 3\n",
    "kgrams = nltk.ngrams(sentence.split(), n)\n",
    "for grams in kgrams:\n",
    "  print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#Create your bigrams or trigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "tgs = nltk.trigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "fdist_3 = nltk.FreqDist(tgs)\n",
    "\n",
    "#for k,v in fdist.items():\n",
    "#    print (k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37516, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(,, and)</td>\n",
       "      <td>1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(., I)</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(;, and)</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(., We)</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(., It)</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., ``)</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(,, '')</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Frequency\n",
       "0    (,, and)       1859\n",
       "1   (of, the)        318\n",
       "2      (., I)        293\n",
       "3   (in, the)        278\n",
       "4    (;, and)        233\n",
       "5     (., We)        227\n",
       "6     (., It)        220\n",
       "7     (., ``)        207\n",
       "8     (,, '')        182\n",
       "9  (and, the)        180"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "print(fdist_df.shape)\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>(from, affectation)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>(affectation, -)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>(often, wished)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>(able, .)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>(us, anecdotes)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Word  Frequency\n",
       "10000  (from, affectation)          1\n",
       "10001     (affectation, -)          1\n",
       "10002      (often, wished)          1\n",
       "10003            (able, .)          1\n",
       "10004      (us, anecdotes)          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df.iloc[10000:10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64316, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(,, and, the)</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(,, and, then)</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(it, ,, and)</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(., It, was)</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(,, and, he)</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(,, and, we)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(,, and, I)</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(,, and, ,)</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(., He, said)</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(., It, is)</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Frequency\n",
       "0   (,, and, the)        121\n",
       "1  (,, and, then)         83\n",
       "2    (it, ,, and)         72\n",
       "3    (., It, was)         69\n",
       "4    (,, and, he)         66\n",
       "5    (,, and, we)         57\n",
       "6     (,, and, I)         55\n",
       "7     (,, and, ,)         54\n",
       "8   (., He, said)         53\n",
       "9     (., It, is)         47"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df = pd.DataFrame(fdist_3.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "print(fdist_df.shape)\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>(pipes, go, out)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>(go, out, -)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>(out, -, till)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>(till, we, ,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>(we, ,, common-place)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Word  Frequency\n",
       "10000       (pipes, go, out)          1\n",
       "10001           (go, out, -)          1\n",
       "10002         (out, -, till)          1\n",
       "10003          (till, we, ,)          1\n",
       "10004  (we, ,, common-place)          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df.iloc[10000:10005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning-up  N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating puctuation and case sensitivity from N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = nltk.tokenize.word_tokenize(raw)\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "word_list = []\n",
    "\n",
    "# Filter out words that have punctuation and make everything lower-case\n",
    "cleaned_words = [w.lower() for w in tokens if w.isalnum()]\n",
    "\n",
    "bgs = [b for b in nltk.bigrams(cleaned_words)]\n",
    "tgs = [b for b in nltk.trigrams(cleaned_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(it, was)</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(and, i)</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(and, then)</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(the, river)</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0     (of, the)        329\n",
       "1     (in, the)        294\n",
       "2     (it, was)        261\n",
       "3    (and, the)        191\n",
       "4     (on, the)        181\n",
       "5     (to, the)        175\n",
       "6      (and, i)        145\n",
       "7   (and, then)        140\n",
       "8      (to, be)        130\n",
       "9  (the, river)        127"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "fdist_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(it, was, a)</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, boat, and)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(george, and, i)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(said, it, was)</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(he, said, he)</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(a, bit, of)</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(one, of, the)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(harris, and, i)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(that, it, was)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(and, then, he)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency\n",
       "0      (it, was, a)         52\n",
       "1  (the, boat, and)         32\n",
       "2  (george, and, i)         30\n",
       "3   (said, it, was)         28\n",
       "4    (he, said, he)         27\n",
       "5      (a, bit, of)         27\n",
       "6    (one, of, the)         25\n",
       "7  (harris, and, i)         25\n",
       "8   (that, it, was)         24\n",
       "9   (and, then, he)         21"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_3 = nltk.FreqDist(tgs)\n",
    "fdist_df = pd.DataFrame(fdist_3.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating puctuation, case sensitivity and stop-words from N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = nltk.tokenize.word_tokenize(raw)\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "word_list = []\n",
    "\n",
    "# Filter out words that have punctuation and make everything lower-case\n",
    "cleaned_words = [w.lower() for w in tokens if w.isalnum()]\n",
    "\n",
    "bgs = [b for b in nltk.bigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords]\n",
    "tgs = [b for b in nltk.trigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords and b[2] not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(harris, said)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(george, said)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(said, george)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(would, go)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(one, another)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(five, minutes)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(said, oh)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(said, harris)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(young, men)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(would, come)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  Frequency\n",
       "0   (harris, said)         41\n",
       "1   (george, said)         34\n",
       "2   (said, george)         22\n",
       "3      (would, go)         17\n",
       "4   (one, another)         17\n",
       "5  (five, minutes)         16\n",
       "6       (said, oh)         16\n",
       "7   (said, harris)         15\n",
       "8     (young, men)         14\n",
       "9    (would, come)         13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "fdist_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(rule, tom, and)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(tom, tom, you)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(right, tom, we)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(cheeses, tom, bought)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(tom, bought, them)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(tom, say, about)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(hi, tom, dick)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(tom, dick, ca)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(matter, tom, replied)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(tom, replied, joe)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Word  Frequency\n",
       "0        (rule, tom, and)          1\n",
       "1         (tom, tom, you)          1\n",
       "2        (right, tom, we)          1\n",
       "3  (cheeses, tom, bought)          1\n",
       "4     (tom, bought, them)          1\n",
       "5       (tom, say, about)          1\n",
       "6         (hi, tom, dick)          1\n",
       "7         (tom, dick, ca)          1\n",
       "8  (matter, tom, replied)          1\n",
       "9     (tom, replied, joe)          1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_3 = nltk.FreqDist(tgs)\n",
    "fdist_df = pd.DataFrame(fdist_3.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating targeted N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = nltk.tokenize.word_tokenize(raw)\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "word_list = []\n",
    "\n",
    "# Filter out words that have punctuation and make everything lower-case\n",
    "cleaned_words = [w.lower() for w in tokens if w.isalnum()]\n",
    "\n",
    "bgs = [b for b in nltk.bigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords and \\\n",
    "       (b[0] == 'tom' or b[1] == 'tom')]\n",
    "\n",
    "tgs = [b for b in nltk.trigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords and \\\n",
    "       (b[0] == 'tom' or b[1] == 'tom' or b[2] == 'tom')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = nltk.tokenize.word_tokenize(raw)\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "word_list = []\n",
    "\n",
    "# Filter out words that have punctuation and make everything lower-case\n",
    "cleaned_words = [w.lower() for w in tokens if w.isalnum()]\n",
    "\n",
    "bgs = [b for b in nltk.bigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords and \\\n",
    "       (b[0] == 'harris' or b[1] == 'harris')]\n",
    "\n",
    "tgs = [b for b in nltk.trigrams(cleaned_words) if b[0] not in stopwords and b[1] not in stopwords and \\\n",
    "       (b[0] == 'harris' or b[1] == 'harris' or b[2] == 'harris')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(harris, said)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(said, harris)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(harris, would)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(harris, told)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(george, harris)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(harris, never)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(time, harris)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(met, harris)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(harris, sat)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(cried, harris)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency\n",
       "0    (harris, said)         41\n",
       "1    (said, harris)         15\n",
       "2   (harris, would)          5\n",
       "3    (harris, told)          4\n",
       "4  (george, harris)          4\n",
       "5   (harris, never)          3\n",
       "6    (time, harris)          3\n",
       "7     (met, harris)          3\n",
       "8     (harris, sat)          3\n",
       "9   (cried, harris)          3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "fdist_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(harris, said, he)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(harris, said, that)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(harris, said, it)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(said, harris, and)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(harris, said, oh)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(ago, harris, said)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(harris, said, how)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(harris, sat, on)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(said, harris, then)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(harris, said, i)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word  Frequency\n",
       "0    (harris, said, he)         11\n",
       "1  (harris, said, that)          7\n",
       "2    (harris, said, it)          5\n",
       "3   (said, harris, and)          4\n",
       "4    (harris, said, oh)          3\n",
       "5   (ago, harris, said)          2\n",
       "6   (harris, said, how)          2\n",
       "7     (harris, sat, on)          2\n",
       "8  (said, harris, then)          2\n",
       "9     (harris, said, i)          2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_3 = nltk.FreqDist(tgs)\n",
    "fdist_df = pd.DataFrame(fdist_3.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating N-Grams of custom length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fourgrams = nltk.ngrams(raw.split(), n)\n",
    "\n",
    "n = 5\n",
    "fivegrams = nltk.ngrams(raw.split(), n)\n",
    "\n",
    "n = 6\n",
    "sixgrams = nltk.ngrams(raw.split(), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(the, bottom, of, the)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(at, the, bottom, of)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(in, the, middle, of)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(the, middle, of, the)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(said, it, was, a)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(and, Harris, and, I)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(a, good, deal, of)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(He, said, he, had)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(and, George, and, I)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(the, end, of, the)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Word  Frequency\n",
       "0  (the, bottom, of, the)         12\n",
       "1   (at, the, bottom, of)         11\n",
       "2   (in, the, middle, of)         10\n",
       "3  (the, middle, of, the)         10\n",
       "4      (said, it, was, a)          9\n",
       "5   (and, Harris, and, I)          8\n",
       "6     (a, good, deal, of)          8\n",
       "7     (He, said, he, had)          8\n",
       "8   (and, George, and, I)          8\n",
       "9     (the, end, of, the)          6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_4 = nltk.FreqDist(fourgrams)\n",
    "fdist_4_df = pd.DataFrame(fdist_4.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_4_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(at, the, bottom, of, the)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(in, the, middle, of, the)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(He, said, he, had, never)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(we, were, going, to, have)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, opposite, side, of, the)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(in, the, nose, of, the)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(the, nose, of, the, boat,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(the, other, side, of, the)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(and, asked, him, if, he)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(I, don't, think, I, ever)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Word  Frequency\n",
       "0      (at, the, bottom, of, the)         10\n",
       "1      (in, the, middle, of, the)          6\n",
       "2      (He, said, he, had, never)          5\n",
       "3     (we, were, going, to, have)          4\n",
       "4  (the, opposite, side, of, the)          4\n",
       "5        (in, the, nose, of, the)          3\n",
       "6     (the, nose, of, the, boat,)          3\n",
       "7     (the, other, side, of, the)          3\n",
       "8       (and, asked, him, if, he)          3\n",
       "9      (I, don't, think, I, ever)          3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_5 = nltk.FreqDist(fivegrams)\n",
    "fdist_5_df = pd.DataFrame(fdist_5.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_5_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(in, the, nose, of, the, boat,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(if, it, had, not, been, for)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(at, the, bottom, of, the, boat,)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(when, we, had, given, up, all)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(it, was, my, liver, that, was)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(was, my, liver, that, was, out)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(my, liver, that, was, out, of)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(you, are, going, to, have, a)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(him, at, the, bottom, of, the)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(know, a, place, round, the, corner)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Word  Frequency\n",
       "0       (in, the, nose, of, the, boat,)          3\n",
       "1         (if, it, had, not, been, for)          3\n",
       "2     (at, the, bottom, of, the, boat,)          3\n",
       "3       (when, we, had, given, up, all)          3\n",
       "4       (it, was, my, liver, that, was)          2\n",
       "5      (was, my, liver, that, was, out)          2\n",
       "6       (my, liver, that, was, out, of)          2\n",
       "7        (you, are, going, to, have, a)          2\n",
       "8       (him, at, the, bottom, of, the)          2\n",
       "9  (know, a, place, round, the, corner)          2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_6 = nltk.FreqDist(sixgrams)\n",
    "fdist_6_df = pd.DataFrame(fdist_6.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_6_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(directory+'n_grams_out.xlsx')\n",
    "fdist_4_df.to_excel(writer,'FourGrams')\n",
    "fdist_5_df.to_excel(writer,'FiveGrams')\n",
    "fdist_6_df.to_excel(writer,'SixGrams')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
